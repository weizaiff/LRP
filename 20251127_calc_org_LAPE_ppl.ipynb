{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cac2bd6-46d4-4ec9-96ec-e3502d17c0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n20251127:\\n    load llama2的语言神经元&计算ppl\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "20251127:\n",
    "    load llama2的语言神经元&计算ppl\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dd4228c-e8a0-4531-87a7-1a58caf9a315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting datasets\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/3b/5e/6f8d874366788ad5d549e9ba258037d974dda6e004843be1bda794571701/datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /root/miniconda3/lib/python3.12/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.12/site-packages (from datasets) (2.2.6)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/13/95/aec81f781c75cd10554dc17a25849c720d54feafb6f7847690478dcf5ef8/pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dill<0.4.1,>=0.3.0 in /root/miniconda3/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e5/63/cd7d615331b328e287d8233ba9fdf191a9c2d11b6af0c7a59cfcec23de68/pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.32.2 (from datasets)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/1e/db/4254e3eabe8020b458f1a747140d32277ec7a271daf1d235b70dc0b4e6e3/requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpx<1.0.0 in /root/miniconda3/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/11/4f/426f91b96701ec2f37bb2b8cec664eff4f658a11f3fa9d94f0a887ea6d2b/xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.9/193.9 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/bf/b6/5f922792be93b82ec6b5f270bbb1ef031fd0622847070bbcf9da816502cc/multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /root/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /root/miniconda3/lib/python3.12/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /root/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /root/miniconda3/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /root/miniconda3/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /root/miniconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/miniconda3/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /root/miniconda3/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Installing collected packages: pytz, xxhash, tzdata, tqdm, requests, pyarrow, multiprocess, pandas, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.2\n",
      "    Uninstalling tqdm-4.66.2:\n",
      "      Successfully uninstalled tqdm-4.66.2\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "vllm 0.11.2 requires transformers<5,>=4.56.0, but you have transformers 4.52.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-4.4.1 multiprocess-0.70.18 pandas-2.3.3 pyarrow-22.0.0 pytz-2025.2 requests-2.32.5 tqdm-4.67.1 tzdata-2025.2 xxhash-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00627947-5528-4a01-8f46-fd42a332212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import os\n",
    "# download checkpoint\n",
    "from accelerate import load_checkpoint_and_dispatch\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # To prevent long warnings :)\n",
    "\n",
    "#from accelerate import load_checkpoint_and_dispatch\n",
    "\n",
    "from accelerate import init_empty_weights\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import util\n",
    "import importlib\n",
    "\n",
    "importlib.reload(util)      # 只能 reload 模块本身\n",
    "from util import calc_ppl, get_test_data   # reload 后再重新 import 函数\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90158885-707f-425e-9a0f-06752432fdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint):\n",
    "    config = AutoConfig.from_pretrained(checkpoint,trust_remote_code=True)\n",
    "    print('checkpoint:', checkpoint)\n",
    "    \n",
    "    \n",
    "    if True:\n",
    "    \n",
    "        device_map='cuda'\n",
    "        model= AutoModelForCausalLM.from_pretrained(checkpoint, trust_remote_code=True, torch_dtype= torch.bfloat16,device_map=device_map ) # for download model weight\n",
    "    \n",
    "    else:\n",
    "        with init_empty_weights():\n",
    "            model = AutoModelForCausalLM.from_config(config, trust_remote_code=True)\n",
    "    \n",
    "        model = load_checkpoint_and_dispatch(\n",
    "            model, checkpoint, device_map=\"auto\", dtype=torch.bfloat16#, no_split_module_classes=[\"GPTJBlock\"]\n",
    "        )\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)#AutoTokenizer.from_pretrained(\"/home/work/lyftri/projects/model_zoo/compass_sea_13b_s4_merge2HF_org_convert_TP_1_PP_2\",  trust_remote_code=True)#AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1546710-3433-4200-b485-7e704dd71f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22e8c781-e2bb-4da9-8e6f-a2bf89f84100",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_mask_neuron_model(model, activation_mask_path, need_lang):\n",
    "\n",
    "    if activation_mask_path:\n",
    "        activation_masks = torch.load(activation_mask_path)\n",
    "    else:\n",
    "        activation_masks = [None]\n",
    "    \n",
    "    final_output = []\n",
    "    if is_llama:\n",
    "        languages = [\"en\", \"zh\", \"fr\", \"es\", \"vi\", \"id\", \"ja\"]\n",
    "    else:\n",
    "        languages = [\"en\", \"zh\", \"fr\", \"es\", \"vi\", \"id\"]\n",
    "    \n",
    "    need_lang = [need_lang]#['en', 'zh', 'vi']\n",
    "    \n",
    "    for activation_mask, mask_lang in zip(activation_masks, languages):\n",
    "    \n",
    "        if mask_lang not in need_lang:continue\n",
    "            \n",
    "        print(f'get mask =====lang:{mask_lang}=====')\n",
    "    \n",
    "        \n",
    "        if activation_mask:\n",
    "            def factory(mask):\n",
    "                def llama_forward_org(self, x):\n",
    "                    gate_up, _ = self.gate_up_proj(x)  # b, l, 2i\n",
    "                    i = gate_up.size(-1)\n",
    "                    activation = F.silu(gate_up[:, :, : i // 2])\n",
    "                    activation.index_fill_(2, mask, 0)\n",
    "                    x = activation * gate_up[:, :, i // 2 :]\n",
    "                    x, _ = self.down_proj(x)\n",
    "                    return x\n",
    "                def llama_forward(self, x):\n",
    "                    gate_ = self.gate_proj(x)  # b, l, 2i\n",
    "                    i = gate_.size(-1)\n",
    "                    activation = F.silu(gate_)\n",
    "                    activation.index_fill_(2, mask, 0)\n",
    "                    x = activation * self.up_proj(x)\n",
    "                    x = self.down_proj(x)\n",
    "                    return x\n",
    "    \n",
    "                def bloom_forward(self, x: torch.Tensor):\n",
    "                    x, _ = self.dense_h_to_4h(x)\n",
    "                    x = self.gelu_impl(x)\n",
    "                    x.index_fill_(2, mask, 0)\n",
    "                    x, _ = self.dense_4h_to_h(x)\n",
    "                    return x\n",
    "    \n",
    "                if is_llama:\n",
    "                    return llama_forward\n",
    "                else:\n",
    "                    return bloom_forward\n",
    "    \n",
    "            for i, layer_mask in enumerate(activation_mask):\n",
    "                if is_llama:\n",
    "                    obj = model.model.layers[i].mlp\n",
    "                else:\n",
    "                    obj = model.model.layers[i].mlp\n",
    "                obj.forward = MethodType(factory(layer_mask.to('cuda')), obj)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb1058f0-2808-4bdd-8169-4a28753e190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: /root/autodl-fs/model_zoo/meta-llama/Llama-2-7b-hf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e25b3878ce47a5af3aaaf5065f9395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argparse\n",
    "from types import MethodType\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_path ='/root/autodl-fs/model_zoo/meta-llama/Llama-2-7b-hf'\n",
    "activation_mask_path='/root/autodl-fs/Language-Specific-Neurons/LLaMA-2-7B.neuron.pth'\n",
    "\n",
    "is_llama = bool(model_path.find('llama') >= 0)\n",
    "model, tokenizer = load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c6343-256a-46f8-8ee9-70e429feb502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "934ae8f4-eb7f-40d6-81cf-a362819a8fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "********************\n",
      "model name: org_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:53<00:00, 18.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.5736, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:21<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(14.1997, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:39<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.3294, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_en\n",
      "get mask =====lang:en=====\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:53<00:00, 18.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.5102, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:20<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(13.7195, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:39<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.0321, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_vi\n",
      "get mask =====lang:vi=====\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:53<00:00, 18.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.5556, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:20<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(12.9547, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:39<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.6875, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_zh\n",
      "get mask =====lang:zh=====\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:53<00:00, 18.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.3950, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:20<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(13.4718, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:39<00:00, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.2067, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "test_en = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/en_radom_1000_test.jsonl')\n",
    "test_vi = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/vi_radom_1000_test.jsonl')\n",
    "test_zh = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/zh_radom_1000_test.jsonl')\n",
    "               \n",
    "# calc ppl\n",
    "model_list= [\n",
    "    (model, 'org_model'),\n",
    "    (None, 'mask_en'),\n",
    "    (None, 'mask_vi'),\n",
    "    (None, 'mask_zh'),\n",
    "]\n",
    "\n",
    "data_list = [\n",
    "    (test_en, 'en_data'),\n",
    "    (test_vi, 'vi_data'),\n",
    "    (test_zh, 'zh_data')\n",
    "    \n",
    "]\n",
    "\n",
    "for i_model, model_name in model_list:\n",
    "    print('*'*20)\n",
    "    print('*'*20)\n",
    "    print('model name:', model_name)\n",
    "\n",
    "    if model_name != 'org_model':\n",
    "        i_model = get_mask_neuron_model(model, activation_mask_path, model_name.split('_')[-1])\n",
    "\n",
    "    for i_data, data_name in data_list:\n",
    "        print('='*20)\n",
    "        print('data name:', data_name)\n",
    "        ppl_sum, ppl_count = calc_ppl(i_model, tokenizer, i_data, max_len= 2048)\n",
    "        print('ppl:',ppl_sum/ppl_count )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db1bd67-8ada-480b-b4ac-8dae58dfed96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "238c7fdf-735b-4a43-9cd1-bf4bf8ddf3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "********************\n",
      "model name: org_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:52<00:00, 18.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.5736, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:21<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(14.1997, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:39<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.3294, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_zh\n",
      "get mask =====lang:zh=====\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:53<00:00, 18.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.3950, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:20<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(13.4718, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:39<00:00, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.2067, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "test_en = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/en_radom_1000_test.jsonl')\n",
    "test_vi = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/vi_radom_1000_test.jsonl')\n",
    "test_zh = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/zh_radom_1000_test.jsonl')\n",
    "               \n",
    "# calc ppl\n",
    "model_list= [\n",
    "    (model, 'org_model'),\n",
    "    #(None, 'mask_en'),\n",
    "    #(None, 'mask_vi'),\n",
    "    (None, 'mask_zh'),\n",
    "]\n",
    "\n",
    "data_list = [\n",
    "    (test_en, 'en_data'),\n",
    "    (test_vi, 'vi_data'),\n",
    "    (test_zh, 'zh_data')\n",
    "    \n",
    "]\n",
    "\n",
    "for i_model, model_name in model_list:\n",
    "    print('*'*20)\n",
    "    print('*'*20)\n",
    "    print('model name:', model_name)\n",
    "\n",
    "    if model_name != 'org_model':\n",
    "        i_model = get_mask_neuron_model(model, activation_mask_path, model_name.split('_')[-1])\n",
    "\n",
    "    for i_data, data_name in data_list:\n",
    "        print('='*20)\n",
    "        print('data name:', data_name)\n",
    "        ppl_sum, ppl_count = calc_ppl(i_model, tokenizer, i_data, max_len= 2048)\n",
    "        print('ppl:',ppl_sum/ppl_count )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45da724-82c6-4639-8163-0e85c802d446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a650f70-b301-4a7b-bfde-86b3acfcc40a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
