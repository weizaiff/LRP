{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66f8a83-e87d-4da4-8d01-6f689f7cb24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    20251124:\\n        把一些神经元mask掉，再看看generation\\n    20251125:\\n        峰度的top1% ---> bottom 1%\\n        gap rate top & bottom 1% test\\n    20251202:\\n        open ended generation test\\n        calc LRP_based method\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    20251124:\n",
    "        把一些神经元mask掉，再看看generation\n",
    "    20251125:\n",
    "        峰度的top1% ---> bottom 1%\n",
    "        gap rate top & bottom 1% test\n",
    "    20251202:\n",
    "        open ended generation test\n",
    "        calc LRP_based method\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ec4d08-fa6a-4ae2-a5a4-00aedec2f604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import transformers\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import os\n",
    "# download checkpoint\n",
    "from accelerate import load_checkpoint_and_dispatch\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # To prevent long warnings :)\n",
    "\n",
    "#from accelerate import load_checkpoint_and_dispatch\n",
    "\n",
    "from accelerate import init_empty_weights\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ccdc958-9ef5-4565-91ce-91c3de3b7fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "352d7f56-4ec1-4edd-a2bd-5d2ee384bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0279e997-1e63-4fdf-b360-5816aa1575b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import importlib\n",
    "\n",
    "importlib.reload(util)      # 只能 reload 模块本身\n",
    "from util import calc_ppl, get_test_data   # reload 后再重新 import 函数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bdba13-ef65-4432-9908-ccf3d995518d",
   "metadata": {},
   "source": [
    "# function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb6ed64-7229-4ff7-9c7a-39ad1719b236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d03ac7d9-4627-4ede-b09e-c485db6065f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint):\n",
    "    config = AutoConfig.from_pretrained(checkpoint,trust_remote_code=True)\n",
    "    print('checkpoint:', checkpoint)\n",
    "    \n",
    "    \n",
    "    if True:\n",
    "    \n",
    "        device_map='auto'\n",
    "        model= AutoModelForCausalLM.from_pretrained(checkpoint, trust_remote_code=True, torch_dtype= torch.bfloat16,device_map=device_map,weights_only=False ) # for download model weight\n",
    "    \n",
    "    else:\n",
    "        with init_empty_weights():\n",
    "            model = AutoModelForCausalLM.from_config(config, trust_remote_code=True)\n",
    "    \n",
    "        model = load_checkpoint_and_dispatch(\n",
    "            model, checkpoint, device_map=\"auto\", dtype=torch.bfloat16#, no_split_module_classes=[\"GPTJBlock\"]\n",
    "        )\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)#AutoTokenizer.from_pretrained(\"/home/work/lyftri/projects/model_zoo/compass_sea_13b_s4_merge2HF_org_convert_TP_1_PP_2\",  trust_remote_code=True)#AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "def set_neuron_zero(model, neuron_list):\n",
    "    '''\n",
    "    将指定的neuron设置为zero\n",
    "\n",
    "    '''\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    for ikey,_ in neuron_list:\n",
    "        w_name = ikey.split('_index_')[0]\n",
    "        neuron_index = int(ikey.split('_index_')[1])\n",
    "\n",
    "        #set zero\n",
    "        state_dict[w_name][neuron_index,:] =0 #1 #0 #-1  #-63.75#0\n",
    "    return model\n",
    "    \n",
    "\n",
    "\n",
    "def generate(model, tokenizer, textlist):\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #textlist=[\"The garden blooms with vibrant colors, a gentle breeze carries the scent of roses, and the sun casts a warm glow.\"] # maxlen 64\n",
    "    #textlist=['智慧殿堂中，书籍如海，知识无尽，探索永恒。艾拉追寻历史，灵感无限']# maxlen 64\n",
    "    #textlist=['你是']# maxlen 64\n",
    "    \n",
    "    #textlist=['The garden blooms with vibrant colors, a gentle breeze carries the scent of roses, and the sun casts a warm glow.']\n",
    "    #textlist=['China is']\n",
    "    bar = tqdm(total=len(textlist))\n",
    "    \n",
    "    \n",
    "    device='cuda' # cpu cuda\n",
    "    for itext in textlist:\n",
    "        print('*'*20)\n",
    "        input_text = itext\n",
    "        print('input:', input_text)\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "        print('input_ids:', input_ids)\n",
    "    \n",
    "        outputs = model.generate(**input_ids, do_sample=False, num_beams=1, max_new_tokens=128) #max_length \n",
    "        print('outputs:', outputs)\n",
    "        print('output:',tokenizer.batch_decode(outputs, skip_special_tokens=False))\n",
    "        bar.update(1)\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d741764e-9088-4627-9eba-84e9680b3d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c9444d-011b-4dce-88e8-2822a7aa71c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f23c3-28fa-425d-9854-21608107679e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b949cc5-8e4e-46c3-815c-0dc92450fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model('/root/autodl-fs/model_zoo/meta-llama/Llama-2-7b-chat-hf') #load_model('/root/autodl-fs/model_zoo/google/gemma-3-1b-it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1df2af-da89-4166-93f7-c3088168ba92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6b3edc6-1539-40d1-a7ac-a4d60048f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_en = torch.load('/root/autodl-fs/LRP_kur_res/20251202_llama2_7b_chat/bottom1perc_LRP_kur_res_en.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93683ce9-c877-4a61-9c00-b752f310881c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model.layers.0.mlp.up_proj.weight_index_7391', -0.30401533791557656),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_8880', -0.29782008829647033),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_6352', -0.26962193885607144),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_9710', -0.23214666906107517),\n",
       " ('model.layers.4.mlp.up_proj.weight_index_3661', -0.12755914166374138),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_2425', -0.11200394791978541),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_9710', -0.10520611510249811),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_9651', -0.09108095855852305),\n",
       " ('model.layers.14.mlp.gate_proj.weight_index_4032', -0.08547839202870167),\n",
       " ('model.layers.4.mlp.up_proj.weight_index_2982', -0.08328656704131499),\n",
       " ('model.layers.4.mlp.up_proj.weight_index_4505', -0.08160818501010603),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_2371', -0.07463792617198806),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_119', -0.07071792819615519),\n",
       " ('model.layers.4.mlp.up_proj.weight_index_1542', -0.06558213877290697),\n",
       " ('model.layers.4.mlp.up_proj.weight_index_8462', -0.04247547294752696),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_1457', -0.039988208734492936),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_4012', -0.03823500991082218),\n",
       " ('model.layers.15.mlp.gate_proj.weight_index_1288', -0.03762118886915289),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_1506', -0.037439211868194544),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_9258', -0.03569756284586223),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_4510', -0.022665205860496584),\n",
       " ('model.layers.4.mlp.gate_proj.weight_index_2982', -0.020454285072687206),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_9818', -0.00147281635898322),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_4395', 0.010504237641432379),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_3136', 0.015453018344953495),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_10642', 0.016321706900256583),\n",
       " ('model.layers.15.mlp.gate_proj.weight_index_9048', 0.02315007071332209),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_10054', 0.03059861235904382),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_1530', 0.037398999125678234),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_9686', 0.04372338239996276),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_1300', 0.04787190950815967),\n",
       " ('model.layers.2.mlp.gate_proj.weight_index_1856', 0.05421234886142923),\n",
       " ('model.layers.19.mlp.gate_proj.weight_index_8681', 0.062224416542893124),\n",
       " ('model.layers.2.mlp.up_proj.weight_index_10974', 0.06406783265838278),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_408', 0.06905887348301576),\n",
       " ('model.layers.4.mlp.gate_proj.weight_index_738', 0.06918905362097583),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_5794', 0.07593220203196838),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_2198', 0.0765064805655018),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_3832', 0.07761166087311233),\n",
       " ('model.layers.4.mlp.up_proj.weight_index_10965', 0.08231712448442119),\n",
       " ('model.layers.1.mlp.up_proj.weight_index_4893', 0.0837165110915361),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_925', 0.084816143963935),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_662', 0.08510201612784796),\n",
       " ('model.layers.7.mlp.gate_proj.weight_index_3832', 0.09765664945253372),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_9945', 0.09892080648778956),\n",
       " ('model.layers.2.mlp.up_proj.weight_index_1058', 0.10188742989018396),\n",
       " ('model.layers.14.mlp.gate_proj.weight_index_2390', 0.10617300666517204),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_4874', 0.10714196059895542),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_4445', 0.10801041477908191),\n",
       " ('model.layers.11.mlp.down_proj.weight_index_3085', 0.1085640307589597),\n",
       " ('model.layers.16.mlp.up_proj.weight_index_6874', 0.11000334697116143),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_997', 0.11144199498987994),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_8446', 0.11405889395015523),\n",
       " ('model.layers.15.mlp.gate_proj.weight_index_8903', 0.11422809622257946),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_680', 0.11628034672033616),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_5133', 0.1171976319893524),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_397', 0.11807268268502957),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_8962', 0.12034876299323694),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_6867', 0.12448066981398487),\n",
       " ('model.layers.19.mlp.gate_proj.weight_index_99', 0.12474385939313715),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_1828', 0.12495360824635382),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_7975', 0.12595152779307428),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_9027', 0.12659161488110238),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_8362', 0.12784535281216414),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_4746', 0.1279470249755157),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_3648', 0.12815441211328826),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_8222', 0.1282191505325816),\n",
       " ('model.layers.13.mlp.gate_proj.weight_index_1015', 0.12882727132709748),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_2578', 0.13268070490930617),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_2427', 0.13298187888120117),\n",
       " ('model.layers.2.mlp.up_proj.weight_index_2623', 0.13371070516674743),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_4912', 0.1366794205649522),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_965', 0.1371154072446492),\n",
       " ('model.layers.14.mlp.down_proj.weight_index_1991', 0.13966736847199135),\n",
       " ('model.layers.5.mlp.down_proj.weight_index_2023', 0.14100839740195603),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_264', 0.14181782106286267),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_9349', 0.14246802244963241),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_685', 0.14569639711143445),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_337', 0.1458794334804221),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_10035', 0.14598342662299402),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_7861', 0.14646357842732272),\n",
       " ('model.layers.2.mlp.gate_proj.weight_index_5259', 0.1469670545614261),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_5017', 0.14829056853290368),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_9247', 0.14870605625592948),\n",
       " ('model.layers.9.mlp.gate_proj.weight_index_5325', 0.14988460323242503),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_4478', 0.15002810214685391),\n",
       " ('model.layers.4.mlp.gate_proj.weight_index_1542', 0.15038307898275072),\n",
       " ('model.layers.1.mlp.up_proj.weight_index_257', 0.15385474184948178),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_8678', 0.15433873354891192),\n",
       " ('model.layers.5.mlp.down_proj.weight_index_3230', 0.15445995965488235),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_2806', 0.15617894019494116),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_3230', 0.15692109899044926),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_9016', 0.15731779119680178),\n",
       " ('model.layers.2.mlp.up_proj.weight_index_5742', 0.15833457116206695),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_1261', 0.16244257920692595),\n",
       " ('model.layers.19.mlp.up_proj.weight_index_4203', 0.16329150601379716),\n",
       " ('model.layers.8.mlp.gate_proj.weight_index_1622', 0.1634644615347094),\n",
       " ('model.layers.2.mlp.up_proj.weight_index_10595', 0.16540125956109097),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1082', 0.16617749411813865),\n",
       " ('model.layers.5.mlp.gate_proj.weight_index_9273', 0.16648622928154788),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_820', 0.16711576782173232),\n",
       " ('model.layers.28.mlp.up_proj.weight_index_8445', 0.17007919507250824),\n",
       " ('model.layers.27.mlp.up_proj.weight_index_7755', 0.17465380205900205),\n",
       " ('model.layers.31.mlp.gate_proj.weight_index_5618', 0.17617986639876637),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_498', 0.1767513864504462),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_8066', 0.17685311625252886),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_6288', 0.17732689819806202),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_7655', 0.1782208452981311),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_5840', 0.17825365015394734),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_6892', 0.17942812430195731),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_3436', 0.17989519438681478),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_1153', 0.18032234705114236),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_1563', 0.18200093130180317),\n",
       " ('model.layers.28.mlp.down_proj.weight_index_2023', 0.18365229869135735),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_915', 0.1848783799051108),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_1633', 0.18704600120285564),\n",
       " ('model.layers.4.mlp.up_proj.weight_index_5895', 0.1873834957934215),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_1115', 0.18863721527409094),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_9258', 0.1911977966666667),\n",
       " ('model.layers.1.mlp.down_proj.weight_index_945', 0.19171396509302951),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_6622', 0.19272076102964508),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_4812', 0.19312399215306053),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_1512', 0.19406412822504127),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_2168', 0.19457982288206432),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_618', 0.1949109966203726),\n",
       " ('model.layers.3.mlp.gate_proj.weight_index_8487', 0.19678656371062386),\n",
       " ('model.layers.28.mlp.up_proj.weight_index_8030', 0.19681628355735636),\n",
       " ('model.layers.31.mlp.gate_proj.weight_index_2574', 0.19708708760495464),\n",
       " ('model.layers.28.mlp.up_proj.weight_index_4001', 0.1994718861607856),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_4260', 0.19978590000520402),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_4538', 0.1998731188184646),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_6377', 0.20037776691326137),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2524', 0.20068953731273087),\n",
       " ('model.layers.28.mlp.down_proj.weight_index_3833', 0.20122879944151117),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_6143', 0.2023606364907784),\n",
       " ('model.layers.15.mlp.gate_proj.weight_index_8832', 0.2034573624009237),\n",
       " ('model.layers.6.mlp.up_proj.weight_index_10686', 0.20399288859900677),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_1412', 0.20423062484564403),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_1527', 0.20426369072048445),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_7377', 0.20431621033875302),\n",
       " ('model.layers.2.mlp.gate_proj.weight_index_10188', 0.2054198726852583),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_9283', 0.2058456177890582),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_4813', 0.20708170785507862),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_192', 0.20731385711783945),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_601', 0.20778051270065134),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_8120', 0.2085464879810166),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_5964', 0.2091040031447835),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_10701', 0.20999940896534808),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_2870', 0.21212896583198937),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_112', 0.2121731206384303),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_7795', 0.21387410640175553),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_3083', 0.21410333047207608),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_9903', 0.2141301015512358),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_2573', 0.21461226006004308),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_6227', 0.21512264634935407),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_10020', 0.21545935714837183),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2292', 0.21615049209706605),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_3271', 0.2188746732815674),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2581', 0.21905364764980995),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_6674', 0.22034626077212893),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_2179', 0.22345340542279857),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_9755', 0.22407704052785116),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_6345', 0.22552177795172712),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_7481', 0.2282466077983023),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_2393', 0.22923628527661188),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_9686', 0.22956496119538183),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_9070', 0.23132422132800823),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_6179', 0.23167218649119325),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1661', 0.23307795889533667),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_3570', 0.23392194513281117),\n",
       " ('model.layers.13.mlp.down_proj.weight_index_2393', 0.2339342958859838),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_9823', 0.23427504867430393),\n",
       " ('model.layers.4.mlp.gate_proj.weight_index_3672', 0.23439020686387613),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_1826', 0.23476400218591031),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_5516', 0.2349217159953052),\n",
       " ('model.layers.13.mlp.down_proj.weight_index_2695', 0.23598884260024855),\n",
       " ('model.layers.28.mlp.down_proj.weight_index_875', 0.23670018861038544),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_912', 0.23694975625013193),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_10543', 0.23719458566826024),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_2298', 0.23800671029363318),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_9055', 0.2393139584297188),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_1087', 0.23946333485134597),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_875', 0.24041438716938757),\n",
       " ('model.layers.13.mlp.down_proj.weight_index_2213', 0.24051971008241857),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_727', 0.24169354849311464),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_3911', 0.24214448581680914),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1751', 0.24242015776095727),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_2050', 0.24266973904414346),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_10327', 0.24287867093418924),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_7441', 0.24377991628674556),\n",
       " ('model.layers.28.mlp.up_proj.weight_index_10421', 0.24423155181540634),\n",
       " ('model.layers.31.mlp.gate_proj.weight_index_10', 0.24730161572295817),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_1936', 0.24873378504614418),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_3287', 0.24892487475198966),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_5807', 0.2502122548117711),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_1260', 0.2504975264050926),\n",
       " ('model.layers.14.mlp.gate_proj.weight_index_9826', 0.2509059937026672),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_2991', 0.2521773469769881),\n",
       " ('model.layers.14.mlp.down_proj.weight_index_1692', 0.2526960035478609),\n",
       " ('model.layers.11.mlp.gate_proj.weight_index_10235', 0.25316304808208834),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_10403', 0.25361374518893376),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_9045', 0.2544513989313675),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_3147', 0.2558946736512784),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_2393', 0.25619921762372044),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_1346', 0.25665320030323846),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_2712', 0.2567599415784656),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_8945', 0.25758488461542317),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_7260', 0.2578527241748314),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_911', 0.2590006264350504),\n",
       " ('model.layers.9.mlp.gate_proj.weight_index_10066', 0.25913210079905813),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_2789', 0.25928001933641776),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_3452', 0.2597914871819449),\n",
       " ('model.layers.25.mlp.down_proj.weight_index_1697', 0.2598041587839437),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1003', 0.25983505654605965),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_7423', 0.26017687993738114),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_3285', 0.2604257745610008),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_7027', 0.26092347665845717),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_1512', 0.2637574475318849),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_3671', 0.26392150819490867),\n",
       " ('model.layers.4.mlp.up_proj.weight_index_9488', 0.2641004745963209),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_1052', 0.2642544003512395),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_2747', 0.2644984517673401),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_9617', 0.2645174210608734),\n",
       " ('model.layers.11.mlp.up_proj.weight_index_9665', 0.2646707064438498),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_10898', 0.2650605763013778),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_857', 0.2652553093964709),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_3951', 0.26585792143790377),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_3628', 0.26613746411687433),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_2264', 0.2669032837359162),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_4330', 0.26696726704321394),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_3059', 0.2676131918171949),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_1512', 0.2678874367453701),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_6340', 0.26866055245013154),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_7105', 0.26869824198628445),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_2789', 0.26885998362622665),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_10765', 0.2691142189681579),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_1333', 0.27001723236034536),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_9324', 0.2702124363538463),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_1820', 0.2709674627244638),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_380', 0.27228615280094903),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_4259', 0.2724202108201439),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_1698', 0.27299710092391294),\n",
       " ('model.layers.25.mlp.down_proj.weight_index_1306', 0.27335811671052923),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_4009', 0.27410544526231995),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_3986', 0.27463659198351786),\n",
       " ('model.layers.20.mlp.up_proj.weight_index_4752', 0.27471660730178016),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_9625', 0.27555102320474933),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_3909', 0.2756372088866019),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_3122', 0.27621826547290595),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_8296', 0.2765949114222237),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_735', 0.27671054696995334),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_964', 0.27765016515937146),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_6049', 0.27771744460043646),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_8834', 0.2777658993090122),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_39', 0.2781713618341555),\n",
       " ('model.layers.4.mlp.gate_proj.weight_index_3784', 0.2782698315034997),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_4460', 0.27889684307924956),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_5412', 0.27893944912054724),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_2198', 0.2802423470929125),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_3585', 0.28082408137516834),\n",
       " ('model.layers.13.mlp.gate_proj.weight_index_3728', 0.28203812239880444),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_3877', 0.28247710706242124),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_1147', 0.2831037930957372),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_7216', 0.28351096456281466),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_5027', 0.2835709596157776),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_6990', 0.2837631301467183),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_5043', 0.28436796147214016),\n",
       " ('model.layers.15.mlp.gate_proj.weight_index_7031', 0.2849978207331336),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_1890', 0.2856681249390114),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_355', 0.2865318981019622),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_3778', 0.28655596002314443),\n",
       " ('model.layers.3.mlp.up_proj.weight_index_895', 0.2868580798608362),\n",
       " ('model.layers.6.mlp.gate_proj.weight_index_7050', 0.287387836153024),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_10037', 0.2874170248981267),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_832', 0.2879318058101257),\n",
       " ('model.layers.16.mlp.gate_proj.weight_index_7661', 0.2881129879979647),\n",
       " ('model.layers.3.mlp.up_proj.weight_index_6807', 0.28847679325422915),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_3913', 0.28887059261023884),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_10361', 0.28917214098898913),\n",
       " ('model.layers.16.mlp.up_proj.weight_index_10139', 0.28974375855213097),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_8302', 0.2902206228935138),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_712', 0.29028631620313705),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_141', 0.29059089019448736),\n",
       " ('model.layers.11.mlp.up_proj.weight_index_10629', 0.2910456238910699),\n",
       " ('model.layers.14.mlp.gate_proj.weight_index_5809', 0.29142839825806366),\n",
       " ('model.layers.14.mlp.gate_proj.weight_index_9392', 0.29199433529987884),\n",
       " ('model.layers.9.mlp.gate_proj.weight_index_2396', 0.2923180663184275),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_9716', 0.29255843236376755),\n",
       " ('model.layers.3.mlp.gate_proj.weight_index_8502', 0.2929342284337384),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_3231', 0.2930264433018337),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_6530', 0.2933075955280322),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_516', 0.29346184840684186),\n",
       " ('model.layers.9.mlp.gate_proj.weight_index_9979', 0.29407912605792186),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_1373', 0.29483465628698413),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_1308', 0.2949493305643971),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_7724', 0.2959126740628695),\n",
       " ('model.layers.28.mlp.down_proj.weight_index_1489', 0.29614374503216867),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_3597', 0.2962453564197389),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_2533', 0.29631816209229056),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_2347', 0.2963268801767951),\n",
       " ('model.layers.29.mlp.up_proj.weight_index_2432', 0.296674013453349),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_4249', 0.2969558600274178),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_779', 0.2973810432111179),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_9315', 0.29768058695820443),\n",
       " ('model.layers.11.mlp.up_proj.weight_index_13', 0.29827984941432106),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_2180', 0.29840362096974227),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_6442', 0.29891567311318656),\n",
       " ('model.layers.14.mlp.down_proj.weight_index_568', 0.2992502828146719),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_3716', 0.29935647028388246),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_7946', 0.30019448854418807),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_1221', 0.30110554952557234),\n",
       " ('model.layers.29.mlp.down_proj.weight_index_1052', 0.3017927973770611),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_3563', 0.3024627895749532),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_10156', 0.30246571700030733),\n",
       " ('model.layers.16.mlp.up_proj.weight_index_8049', 0.30322895592499144),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_6623', 0.30393943883101393),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_8078', 0.30406889568005147),\n",
       " ('model.layers.30.mlp.gate_proj.weight_index_1147', 0.3046155147640137),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_8595', 0.30508217072762855),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_6150', 0.3057800554971539),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_2381', 0.3061648568719497),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_3135', 0.30646465491214636),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_3960', 0.30650536323991684),\n",
       " ('model.layers.20.mlp.gate_proj.weight_index_9851', 0.3070222183456601),\n",
       " ('model.layers.28.mlp.up_proj.weight_index_8640', 0.30703964453934596),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2715', 0.30708960000570773),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_1079', 0.30793604697254207),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_6452', 0.30857089335847165),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_3368', 0.30865890564525467),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_507', 0.3093347833986346),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_2664', 0.3095363176350814),\n",
       " ('model.layers.3.mlp.up_proj.weight_index_3598', 0.3106684115353411),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_3769', 0.3106870490601925),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_10271', 0.3111368208432701),\n",
       " ('model.layers.29.mlp.down_proj.weight_index_3918', 0.3113346861107109),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_2466', 0.3117166447881461),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_6192', 0.31179645726846505),\n",
       " ('model.layers.9.mlp.gate_proj.weight_index_6640', 0.31192060300923075),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_9165', 0.3127925191458161),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_6636', 0.31280354708208824),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_1692', 0.3128312111862379),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_11004', 0.31300894029210635),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_105', 0.3135633352790217),\n",
       " ('model.layers.29.mlp.down_proj.weight_index_1401', 0.31361777141964176),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_6232', 0.3143174578666814),\n",
       " ('model.layers.31.mlp.gate_proj.weight_index_8619', 0.31437699842795164),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_3209', 0.31450173542600357),\n",
       " ('model.layers.3.mlp.up_proj.weight_index_675', 0.3146892950352349),\n",
       " ('model.layers.2.mlp.gate_proj.weight_index_837', 0.31477945507930594),\n",
       " ('model.layers.15.mlp.gate_proj.weight_index_2249', 0.31491385875947264),\n",
       " ('model.layers.10.mlp.gate_proj.weight_index_2846', 0.31506949056649614),\n",
       " ('model.layers.6.mlp.up_proj.weight_index_233', 0.3160056371651998),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_3217', 0.3169988249683575),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_2219', 0.31704524379694776),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_7510', 0.31707301538104904),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_322', 0.31713499922682065),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_5356', 0.3171452621591979),\n",
       " ('model.layers.20.mlp.gate_proj.weight_index_1895', 0.3172342484493442),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_2752', 0.3177138606190306),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_2164', 0.3183308899734971),\n",
       " ('model.layers.17.mlp.gate_proj.weight_index_3062', 0.3189306181663376),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_2977', 0.3191005643457876),\n",
       " ('model.layers.3.mlp.up_proj.weight_index_8167', 0.31932524641077276),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_3674', 0.31958406255327754),\n",
       " ('model.layers.8.mlp.gate_proj.weight_index_4816', 0.3199746932900829),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_4070', 0.32071757901143627),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2496', 0.3209383929551044),\n",
       " ('model.layers.6.mlp.up_proj.weight_index_5373', 0.3214685252651863),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_2937', 0.32147179931555536),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_287', 0.3228053666790789),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_7832', 0.3231305464201215),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_2230', 0.3243630088788456),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_4599', 0.324831064242618),\n",
       " ('model.layers.1.mlp.down_proj.weight_index_186', 0.32484125648998186),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_9873', 0.32551769799279695),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_3055', 0.3274251968299593),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_1622', 0.3281755713250054),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_1300', 0.32823704128617015),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_8102', 0.3293916383461055),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_2165', 0.3296742899235259),\n",
       " ('model.layers.5.mlp.down_proj.weight_index_1115', 0.330591765240436),\n",
       " ('model.layers.17.mlp.up_proj.weight_index_2624', 0.3308538680436284),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_3403', 0.3313085437511183),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_7318', 0.33159787173081545),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_2732', 0.33160200918205796),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_7538', 0.33171360214087553),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_4876', 0.3317156633365208),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_8887', 0.33183043443045523),\n",
       " ('model.layers.4.mlp.gate_proj.weight_index_9259', 0.3320776464034756),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_2393', 0.33217968806175735),\n",
       " ('model.layers.30.mlp.gate_proj.weight_index_1140', 0.3324343885817811),\n",
       " ('model.layers.29.mlp.up_proj.weight_index_739', 0.3329009824495808),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_2828', 0.3329046944752383),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_4729', 0.33325272193209754),\n",
       " ('model.layers.13.mlp.gate_proj.weight_index_7694', 0.3336407331645401),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_1243', 0.3337461581812038),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_4722', 0.3337545903515653),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_1661', 0.33382087530382476),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_292', 0.33396631083256256),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_178', 0.3340895075946202),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_1339', 0.3341190045722575),\n",
       " ('model.layers.20.mlp.up_proj.weight_index_9851', 0.3341951572549484),\n",
       " ('model.layers.7.mlp.gate_proj.weight_index_8731', 0.3346680047026007),\n",
       " ('model.layers.3.mlp.up_proj.weight_index_9213', 0.3347292392364283),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_6088', 0.33495746886685396),\n",
       " ('model.layers.28.mlp.up_proj.weight_index_7873', 0.3350193244183801),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_2092', 0.3352850261388536),\n",
       " ('model.layers.14.mlp.gate_proj.weight_index_21', 0.33567527939509123),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_703', 0.33578356144682564),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_2493', 0.3359869150501593),\n",
       " ('model.layers.5.mlp.up_proj.weight_index_4613', 0.3365921930187463),\n",
       " ('model.layers.28.mlp.down_proj.weight_index_2350', 0.33710324586928575),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_330', 0.3372240606330785),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_7756', 0.33722520612182105),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_5544', 0.3374854951940236),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_6030', 0.3378983462885956),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_7298', 0.33828336205311826),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_6602', 0.33851947199262433),\n",
       " ('model.layers.3.mlp.up_proj.weight_index_3359', 0.3385739705980422),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1351', 0.33880472653956906),\n",
       " ('model.layers.16.mlp.up_proj.weight_index_4323', 0.33889582469543544),\n",
       " ('model.layers.13.mlp.down_proj.weight_index_535', 0.33901125599176485),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_9186', 0.3390877753819974),\n",
       " ('model.layers.11.mlp.up_proj.weight_index_7634', 0.33937125775878174),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_3431', 0.3396072419418159),\n",
       " ('model.layers.14.mlp.down_proj.weight_index_3334', 0.340134393380346),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1991', 0.34013705488104096),\n",
       " ('model.layers.5.mlp.down_proj.weight_index_3431', 0.3404334706038932),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_827', 0.34105801150390613),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_4746', 0.341624179567213),\n",
       " ('model.layers.17.mlp.up_proj.weight_index_6491', 0.34230048177967465),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_3356', 0.34250122602039434),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_1500', 0.34250562575192456),\n",
       " ('model.layers.14.mlp.gate_proj.weight_index_4452', 0.34284914220625096),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_6234', 0.34306916694488265),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_117', 0.3433257443497788),\n",
       " ('model.layers.27.mlp.up_proj.weight_index_7501', 0.3433977972649971),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_2827', 0.3439401744847661),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_10578', 0.34445771773553524),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_1793', 0.34462137610741905),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_167', 0.3449892988549843),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_10459', 0.34508721987646584),\n",
       " ('model.layers.6.mlp.up_proj.weight_index_9544', 0.3458101439250556),\n",
       " ('model.layers.13.mlp.gate_proj.weight_index_8192', 0.34586693989600104),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_427', 0.34657553338055136),\n",
       " ('model.layers.3.mlp.up_proj.weight_index_10526', 0.34672684315893765),\n",
       " ('model.layers.13.mlp.down_proj.weight_index_2270', 0.3468314551703662),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_4988', 0.3471009585060032),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_2836', 0.3475256836331422),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_688', 0.34767101207516937),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_7679', 0.3477288335134081),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_2789', 0.3479013427083961),\n",
       " ('model.layers.25.mlp.down_proj.weight_index_2350', 0.34799527942193276),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_3497', 0.34818546180693133),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_5388', 0.34897115687570013),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_1370', 0.34915367804509945),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_964', 0.3496338848070004),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_3289', 0.3496605644111259),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_1120', 0.3498105100558928),\n",
       " ('model.layers.8.mlp.gate_proj.weight_index_2145', 0.35027440714721036),\n",
       " ('model.layers.18.mlp.gate_proj.weight_index_1144', 0.35053287287793067),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_1422', 0.3506977361881445),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_4269', 0.35117399796829796),\n",
       " ('model.layers.4.mlp.gate_proj.weight_index_2052', 0.35154130065055655),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_626', 0.35177520163581155),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_9663', 0.3519116488638985),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_3618', 0.3523583099678649),\n",
       " ('model.layers.21.mlp.down_proj.weight_index_94', 0.3525326124568342),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_1153', 0.35255138691298615),\n",
       " ('model.layers.21.mlp.up_proj.weight_index_3015', 0.3527550892075757),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_2412', 0.35296674850867404),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_664', 0.35342324873133446),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_3350', 0.35371036887906815),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_4047', 0.353751918238161),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_3729', 0.3539372051348435),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_5266', 0.3542856773949379),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_7377', 0.35464579709191435),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_1145', 0.3547704345939571),\n",
       " ('model.layers.14.mlp.gate_proj.weight_index_5556', 0.3550163692971702),\n",
       " ('model.layers.6.mlp.up_proj.weight_index_10487', 0.35588766056808163),\n",
       " ('model.layers.29.mlp.up_proj.weight_index_7006', 0.35621765522603255),\n",
       " ('model.layers.17.mlp.down_proj.weight_index_2050', 0.35632512402354566),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_8885', 0.35638665441375883),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_3416', 0.3566784998796826),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_8497', 0.3568253410738391),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_183', 0.35698428978756747),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_1601', 0.35763857162506785),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_2393', 0.35767744236765076),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_7987', 0.35775631918670436),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_3608', 0.35843088035633563),\n",
       " ('model.layers.28.mlp.down_proj.weight_index_225', 0.358489502044522),\n",
       " ('model.layers.5.mlp.down_proj.weight_index_2789', 0.3593222364976989),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_913', 0.3597308441759157),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_1039', 0.3601637079246309),\n",
       " ('model.layers.14.mlp.gate_proj.weight_index_9714', 0.36035911245677443),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_9977', 0.3605462370384074),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_10392', 0.3606347298073107),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_2539', 0.3609483933575435),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_8589', 0.361790523521885),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_10081', 0.3636481590942302),\n",
       " ('model.layers.15.mlp.gate_proj.weight_index_937', 0.36398773729538414),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_2139', 0.3641117898956989),\n",
       " ('model.layers.15.mlp.gate_proj.weight_index_4914', 0.36419353883699745),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_1298', 0.364575388357649),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_4765', 0.365059419929441),\n",
       " ('model.layers.25.mlp.down_proj.weight_index_187', 0.3651018798331256),\n",
       " ('model.layers.13.mlp.gate_proj.weight_index_8016', 0.36603264978839345),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_1395', 0.36636231642371),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_2126', 0.36638097872526965),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_1377', 0.3664050727147936),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_149', 0.3671805980889),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_3364', 0.36724740894000485),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_2305', 0.3672712948252759),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_7737', 0.3673823594318244),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_673', 0.36740152557951866),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_936', 0.36755821798551036),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_2358', 0.3678028857483304),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_2549', 0.3680849658679568),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_588', 0.36819907249850914),\n",
       " ('model.layers.27.mlp.up_proj.weight_index_5162', 0.36830359533225243),\n",
       " ('model.layers.11.mlp.down_proj.weight_index_3541', 0.3689471877685606),\n",
       " ('model.layers.4.mlp.gate_proj.weight_index_9266', 0.3689619900097387),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_8514', 0.3690673369734738),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_3529', 0.36948835478100506),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_7161', 0.37013613353138064),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_5834', 0.3701831778978124),\n",
       " ('model.layers.28.mlp.down_proj.weight_index_2294', 0.3706112488955249),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_312', 0.3714072586232091),\n",
       " ('model.layers.23.mlp.down_proj.weight_index_2210', 0.37183449766837207),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_5208', 0.37186771751400993),\n",
       " ('model.layers.11.mlp.up_proj.weight_index_2108', 0.37196692212679405),\n",
       " ('model.layers.20.mlp.up_proj.weight_index_2046', 0.3721611406889118),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_2326', 0.37216848028801586),\n",
       " ('model.layers.28.mlp.down_proj.weight_index_3015', 0.372185217480407),\n",
       " ('model.layers.11.mlp.up_proj.weight_index_1459', 0.37293364629239223),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_1696', 0.3730642449391497),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_1854', 0.3735077329339589),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_5479', 0.373630029702408),\n",
       " ('model.layers.13.mlp.down_proj.weight_index_2864', 0.3740809823562459),\n",
       " ('model.layers.13.mlp.gate_proj.weight_index_3994', 0.3742415950730704),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_3190', 0.3743964503128967),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2249', 0.3744355915376478),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_750', 0.3758068167273776),\n",
       " ('model.layers.21.mlp.down_proj.weight_index_3918', 0.3758476080567186),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_5436', 0.37617541432420776),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_798', 0.3761774693141806),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_2870', 0.3763014303120138),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2157', 0.37694117479350275),\n",
       " ('model.layers.4.mlp.up_proj.weight_index_6522', 0.3778794863047872),\n",
       " ('model.layers.18.mlp.down_proj.weight_index_637', 0.37794108553367955),\n",
       " ('model.layers.11.mlp.up_proj.weight_index_8753', 0.37821278345706233),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_76', 0.3792131711312998),\n",
       " ('model.layers.11.mlp.down_proj.weight_index_396', 0.37924670043932585),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_324', 0.37948985253425427),\n",
       " ('model.layers.17.mlp.down_proj.weight_index_3625', 0.3796088253069998),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_1169', 0.379612208848465),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_9470', 0.3797778776465366),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_1631', 0.38022064629465646),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_3723', 0.38054786428537835),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_2712', 0.3806481249403868),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_1735', 0.380864492736424),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_6404', 0.3810091346349771),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_96', 0.38101124058348956),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_2949', 0.38121928465729793),\n",
       " ('model.layers.29.mlp.down_proj.weight_index_1539', 0.38241996497210895),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_9807', 0.38274577573617385),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_7507', 0.3831062364440485),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_1817', 0.38323807407205734),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_1339', 0.3834109293371939),\n",
       " ('model.layers.5.mlp.gate_proj.weight_index_6246', 0.3836171010196354),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_8301', 0.384016215522887),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_2896', 0.38473238814534394),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_7881', 0.385300539067011),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_311', 0.3853556176564634),\n",
       " ('model.layers.17.mlp.up_proj.weight_index_7155', 0.3854270791297023),\n",
       " ('model.layers.14.mlp.down_proj.weight_index_167', 0.3854764972731881),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_1153', 0.3854940120017307),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_10866', 0.38617209227471605),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_3741', 0.38664263601639437),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_2298', 0.3866830007845685),\n",
       " ('model.layers.1.mlp.up_proj.weight_index_7085', 0.3867255545878501),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_2338', 0.38696592162178023),\n",
       " ('model.layers.6.mlp.gate_proj.weight_index_5511', 0.3872604968703106),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_6515', 0.3873701012910633),\n",
       " ('model.layers.1.mlp.up_proj.weight_index_137', 0.38754890407963316),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_254', 0.3879130151956751),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_4342', 0.3880761725703441),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_4000', 0.38834286066633306),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_7487', 0.38864663449499126),\n",
       " ('model.layers.14.mlp.down_proj.weight_index_964', 0.3889093193685773),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_8617', 0.38894179717026445),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_779', 0.3890574571246561),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_2792', 0.38943054595054916),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_1055', 0.38954536401691264),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_7775', 0.389692821736932),\n",
       " ('model.layers.29.mlp.down_proj.weight_index_3295', 0.390143220823286),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_1456', 0.39039293335448066),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1859', 0.39067273558371163),\n",
       " ('model.layers.27.mlp.up_proj.weight_index_7359', 0.390747557730891),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_6458', 0.3908072732031278),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_2561', 0.3909135993469639),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_6802', 0.39135056887948716),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_4395', 0.3915070588487568),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_2119', 0.3916749658756098),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_352', 0.3918740810656165),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_783', 0.39210517922843025),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1960', 0.39311977318876856),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_726', 0.3935765252911949),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_3368', 0.3935916054997701),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_3570', 0.3941119750953268),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_10714', 0.39449830117146867),\n",
       " ('model.layers.17.mlp.up_proj.weight_index_7219', 0.39472071450258417),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_2789', 0.394791077323168),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_6132', 0.394820555380631),\n",
       " ('model.layers.1.mlp.up_proj.weight_index_940', 0.3949452068984556),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_8527', 0.3953139718022247),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_9558', 0.3956653325470203),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_102', 0.39634668355438096),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_3152', 0.3965773439451179),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_5360', 0.39709515321395106),\n",
       " ('model.layers.29.mlp.down_proj.weight_index_2298', 0.3970975892550359),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_2750', 0.397149020187737),\n",
       " ('model.layers.17.mlp.down_proj.weight_index_94', 0.39731082707650955),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_2208', 0.3980448419968905),\n",
       " ('model.layers.17.mlp.down_proj.weight_index_2393', 0.39807333741720097),\n",
       " ('model.layers.29.mlp.down_proj.weight_index_168', 0.39942312833799054),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_6212', 0.39952106729224024),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_9092', 0.3995852584520212),\n",
       " ('model.layers.23.mlp.down_proj.weight_index_3779', 0.4000557442986965),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_4339', 0.4000908586610681),\n",
       " ('model.layers.31.mlp.gate_proj.weight_index_2581', 0.4002961660791544),\n",
       " ('model.layers.13.mlp.gate_proj.weight_index_10231', 0.4003641026330844),\n",
       " ('model.layers.14.mlp.down_proj.weight_index_495', 0.4006121181590556),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_2409', 0.40137038978048833),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_3570', 0.40228995958759306),\n",
       " ('model.layers.1.mlp.up_proj.weight_index_238', 0.4025838019850463),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_3682', 0.40280929875412097),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_3951', 0.40281922484160226),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_914', 0.40293743146657013),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_1207', 0.40294190100904403),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_6263', 0.403130789606843),\n",
       " ('model.layers.1.mlp.gate_proj.weight_index_4786', 0.4031813844243497),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_16', 0.40340460141493706),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_574', 0.4037852153582815),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1542', 0.40392471646762873),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_10907', 0.40429323378924975),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_1430', 0.40517451022952145),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_768', 0.4054300965783746),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_2084', 0.4055252812293366),\n",
       " ('model.layers.26.mlp.up_proj.weight_index_9264', 0.40556007032933694),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_261', 0.40582977161543754),\n",
       " ('model.layers.25.mlp.down_proj.weight_index_2684', 0.40583714438809704),\n",
       " ('model.layers.31.mlp.gate_proj.weight_index_1921', 0.4060813772321312),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_7722', 0.4061110324647359),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_7403', 0.40720420104203514),\n",
       " ('model.layers.14.mlp.down_proj.weight_index_2829', 0.40756578057275217),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_2903', 0.4076762501580595),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_5204', 0.4079973259929046),\n",
       " ('model.layers.29.mlp.down_proj.weight_index_1351', 0.4083072353615127),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_1931', 0.40989857339272984),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2800', 0.4102154900820487),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_2797', 0.41061189886286265),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_184', 0.4108803320188166),\n",
       " ('model.layers.1.mlp.gate_proj.weight_index_5067', 0.41137946276067483),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_2617', 0.41177227478323974),\n",
       " ('model.layers.29.mlp.down_proj.weight_index_2622', 0.4122310233059321),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_8601', 0.412590637140696),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_631', 0.4128462172277305),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_1994', 0.4132419061881576),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_7677', 0.4136455163251074),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_2130', 0.41395958307863534),\n",
       " ('model.layers.11.mlp.down_proj.weight_index_2319', 0.4142053154500376),\n",
       " ('model.layers.4.mlp.down_proj.weight_index_747', 0.41433266742773034),\n",
       " ('model.layers.8.mlp.gate_proj.weight_index_8279', 0.4144616799726828),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_155', 0.41458094062012973),\n",
       " ('model.layers.24.mlp.down_proj.weight_index_2152', 0.41480089888282556),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_1040', 0.4148598513557036),\n",
       " ('model.layers.28.mlp.down_proj.weight_index_1706', 0.4151457854785541),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_6584', 0.4153628753727179),\n",
       " ('model.layers.29.mlp.down_proj.weight_index_2558', 0.4158075392020155),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1633', 0.41632618843866),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_2349', 0.416507837339239),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_3611', 0.4165268835290217),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_7402', 0.4171596894357741),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_7281', 0.41718387558757586),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_345', 0.41719180519369603),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_3872', 0.41741406607601217),\n",
       " ('model.layers.18.mlp.up_proj.weight_index_9585', 0.4174456984431556),\n",
       " ('model.layers.19.mlp.gate_proj.weight_index_10162', 0.4174872602863946),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_4382', 0.41787190040292144),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_8805', 0.41801394527900815),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_5818', 0.4180471033408568),\n",
       " ('model.layers.5.mlp.up_proj.weight_index_7702', 0.4180939523298126),\n",
       " ('model.layers.5.mlp.down_proj.weight_index_3673', 0.41833834682742665),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_5578', 0.41851840974966903),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_1796', 0.4185987196198524),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1762', 0.4190060691042681),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_2014', 0.41905611533582254),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_531', 0.4190939325142429),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_621', 0.41919705700286425),\n",
       " ('model.layers.11.mlp.gate_proj.weight_index_8718', 0.4201117854507417),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2102', 0.4204051420761772),\n",
       " ('model.layers.14.mlp.down_proj.weight_index_2264', 0.42040859883136683),\n",
       " ('model.layers.17.mlp.down_proj.weight_index_2251', 0.4205306468543415),\n",
       " ('model.layers.21.mlp.down_proj.weight_index_2684', 0.42053134143894777),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_8165', 0.42068757606241336),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_3032', 0.4207728478001469),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_8381', 0.42100344239714715),\n",
       " ('model.layers.13.mlp.down_proj.weight_index_2669', 0.42116654190212355),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_897', 0.42120984444486576),\n",
       " ('model.layers.6.mlp.up_proj.weight_index_3294', 0.42123132373229755),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2113', 0.42136810489575893),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_8028', 0.4214264693785106),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_3090', 0.42157177893598785),\n",
       " ('model.layers.2.mlp.gate_proj.weight_index_387', 0.4216890183033426),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_8500', 0.4220910464766292),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_339', 0.42221515131250875),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_2657', 0.4225370433055158),\n",
       " ('model.layers.4.mlp.up_proj.weight_index_7981', 0.42270340370296644),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_6188', 0.4228732934996655),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_3785', 0.423045938132776),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2337', 0.42312559606097455),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_4071', 0.4232467653019256),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_1049', 0.4233506825729423),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_3391', 0.4234201559485662),\n",
       " ('model.layers.29.mlp.up_proj.weight_index_7865', 0.4236363356960213),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_9443', 0.42432615817990094),\n",
       " ('model.layers.17.mlp.gate_proj.weight_index_1147', 0.42443365137590483),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_10762', 0.4245244996266284),\n",
       " ('model.layers.12.mlp.up_proj.weight_index_5129', 0.4256078777417698),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_2714', 0.4256348548384423),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_2886', 0.4258136933608627),\n",
       " ('model.layers.12.mlp.up_proj.weight_index_4253', 0.42671840010193574),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2441', 0.4268757150105844),\n",
       " ('model.layers.13.mlp.down_proj.weight_index_2754', 0.427241451476978),\n",
       " ('model.layers.22.mlp.down_proj.weight_index_631', 0.42745944550326787),\n",
       " ('model.layers.25.mlp.gate_proj.weight_index_5834', 0.42770531502715414),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_870', 0.4277471433074722),\n",
       " ('model.layers.13.mlp.gate_proj.weight_index_5569', 0.4280179355236511),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_3679', 0.42805276994309516),\n",
       " ('model.layers.13.mlp.down_proj.weight_index_228', 0.4281206482987949),\n",
       " ('model.layers.28.mlp.down_proj.weight_index_3918', 0.4283347445853054),\n",
       " ('model.layers.28.mlp.up_proj.weight_index_1271', 0.4283800088741181),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_2175', 0.4293759193915716),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_950', 0.4293862506817554),\n",
       " ('model.layers.7.mlp.gate_proj.weight_index_2111', 0.4294828561444497),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_5931', 0.42962885622937375),\n",
       " ('model.layers.29.mlp.down_proj.weight_index_2244', 0.4296965678407436),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_2883', 0.4304383209933871),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_6977', 0.43060765116158173),\n",
       " ('model.layers.11.mlp.up_proj.weight_index_9046', 0.4306589045620428),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_513', 0.4309181293020221),\n",
       " ('model.layers.24.mlp.up_proj.weight_index_3534', 0.43112537412905283),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_1314', 0.4313663376728192),\n",
       " ('model.layers.3.mlp.gate_proj.weight_index_9598', 0.4315674608940694),\n",
       " ('model.layers.12.mlp.up_proj.weight_index_1922', 0.43162322228553895),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_85', 0.43176224032625976),\n",
       " ('model.layers.28.mlp.up_proj.weight_index_8094', 0.4317808663123923),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_2376', 0.4318175166325702),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_491', 0.4318472011890444),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_3604', 0.4321280661664404),\n",
       " ('model.layers.11.mlp.up_proj.weight_index_652', 0.4322293695926911),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_2048', 0.4324370506976143),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_2340', 0.4325956715614243),\n",
       " ('model.layers.18.mlp.up_proj.weight_index_322', 0.43295298904803525),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_4056', 0.4332090772313255),\n",
       " ('model.layers.4.mlp.up_proj.weight_index_8865', 0.4338837805436775),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_4075', 0.4341501277278841),\n",
       " ('model.layers.13.mlp.gate_proj.weight_index_956', 0.43452117467027307),\n",
       " ('model.layers.15.mlp.gate_proj.weight_index_10583', 0.43455130067918013),\n",
       " ('model.layers.17.mlp.gate_proj.weight_index_7811', 0.4346321519859888),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_8226', 0.434762441421952),\n",
       " ('model.layers.6.mlp.up_proj.weight_index_10268', 0.43494180609123134),\n",
       " ('model.layers.2.mlp.up_proj.weight_index_6547', 0.43517030490306485),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_10779', 0.43523776925682167),\n",
       " ('model.layers.5.mlp.down_proj.weight_index_2825', 0.4355834798103646),\n",
       " ('model.layers.25.mlp.down_proj.weight_index_3670', 0.4359621002590903),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_1251', 0.43619920732082784),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_3234', 0.43641200785379164),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_6084', 0.4367076455295993),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_1585', 0.43671981084039846),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_4062', 0.4368757523952036),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_3431', 0.4369138895659286),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_1272', 0.4369644636838492),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_2282', 0.43721274459623194),\n",
       " ('model.layers.31.mlp.gate_proj.weight_index_7995', 0.43736514507543234),\n",
       " ('model.layers.16.mlp.up_proj.weight_index_10439', 0.43759673411595124),\n",
       " ('model.layers.10.mlp.gate_proj.weight_index_4716', 0.4379619408722304),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_8575', 0.43813862586791474),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_2648', 0.43819663312105783),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_6325', 0.4382715905242933),\n",
       " ('model.layers.22.mlp.down_proj.weight_index_1401', 0.4383201763086797),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_967', 0.43832609694209523),\n",
       " ('model.layers.25.mlp.down_proj.weight_index_4003', 0.4385019941284871),\n",
       " ('model.layers.31.mlp.gate_proj.weight_index_3093', 0.43876551956232346),\n",
       " ('model.layers.3.mlp.up_proj.weight_index_3955', 0.439189907909181),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1532', 0.4392338580153341),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_964', 0.43923926461024987),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2814', 0.43937183518891043),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_5800', 0.43957975412085837),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_8753', 0.4396655824436704),\n",
       " ('model.layers.11.mlp.up_proj.weight_index_6534', 0.4397342111008222),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_945', 0.4398002804972383),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_1025', 0.43988460227677795),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_629', 0.4399038588277797),\n",
       " ('model.layers.17.mlp.down_proj.weight_index_2287', 0.4400277686180001),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_7200', 0.4401788642343991),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2638', 0.4406718399529659),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_7131', 0.4407734720907266),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_2050', 0.4409153266412398),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_7146', 0.44132701118567663),\n",
       " ('model.layers.4.mlp.gate_proj.weight_index_1608', 0.44137294463351173),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_4098', 0.44137845212885907),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_3626', 0.4414772137185081),\n",
       " ('model.layers.17.mlp.up_proj.weight_index_6399', 0.44153514799996874),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_3593', 0.4416170499067227),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_3275', 0.44231270332391404),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_3870', 0.4423697678005576),\n",
       " ('model.layers.17.mlp.down_proj.weight_index_2573', 0.4429686962927373),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_2384', 0.4430281762732031),\n",
       " ('model.layers.11.mlp.gate_proj.weight_index_613', 0.4430710694648359),\n",
       " ('model.layers.26.mlp.up_proj.weight_index_10404', 0.4430785120619194),\n",
       " ('model.layers.11.mlp.down_proj.weight_index_2323', 0.4432025150943595),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_6636', 0.4432417320170101),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_9121', 0.44327421263549605),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_3343', 0.4437211741734046),\n",
       " ('model.layers.24.mlp.down_proj.weight_index_861', 0.44410161672708837),\n",
       " ('model.layers.28.mlp.up_proj.weight_index_6530', 0.4443737258063116),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_128', 0.44460630720848116),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_94', 0.4446344941956415),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_1244', 0.44475538649186674),\n",
       " ('model.layers.26.mlp.down_proj.weight_index_3779', 0.44493401686324363),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_3360', 0.44502648370918596),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_4891', 0.4451147245103204),\n",
       " ('model.layers.12.mlp.up_proj.weight_index_7428', 0.4452697430111381),\n",
       " ('model.layers.25.mlp.down_proj.weight_index_2023', 0.4453233872035045),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_1758', 0.44541497903031235),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_8981', 0.44573766639204226),\n",
       " ('model.layers.5.mlp.gate_proj.weight_index_4424', 0.44576025642632455),\n",
       " ('model.layers.29.mlp.up_proj.weight_index_1925', 0.44635204878745016),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_835', 0.4464383831218237),\n",
       " ('model.layers.13.mlp.down_proj.weight_index_2822', 0.44660968042399674),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_6714', 0.446744408099105),\n",
       " ('model.layers.25.mlp.up_proj.weight_index_5291', 0.4468746241988941),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_3640', 0.4469030748263809),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_10002', 0.44691976461446004),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_1023', 0.4470080327547108),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_149', 0.44727960578407533),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_1092', 0.44785724603080057),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_2801', 0.4478788960622788),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_851', 0.4483595825549118),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_2669', 0.4485942270352523),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_6173', 0.4495492956838216),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_675', 0.4499063846117437),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_315', 0.45001352108902903),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_76', 0.4500644209990572),\n",
       " ('model.layers.29.mlp.down_proj.weight_index_703', 0.45036010758143696),\n",
       " ('model.layers.11.mlp.up_proj.weight_index_5468', 0.4504256438467582),\n",
       " ('model.layers.7.mlp.gate_proj.weight_index_3723', 0.4508833827609049),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_183', 0.4509310437208658),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_2254', 0.4509577910840159),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_2426', 0.4510892732307408),\n",
       " ('model.layers.25.mlp.down_proj.weight_index_2179', 0.451393961285536),\n",
       " ('model.layers.13.mlp.down_proj.weight_index_41', 0.4515065458047709),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1148', 0.45152157648566815),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_938', 0.4519575972030849),\n",
       " ('model.layers.12.mlp.gate_proj.weight_index_747', 0.4520862234411469),\n",
       " ('model.layers.24.mlp.down_proj.weight_index_1340', 0.4522308758205029),\n",
       " ('model.layers.19.mlp.gate_proj.weight_index_4649', 0.45232668652670194),\n",
       " ('model.layers.4.mlp.up_proj.weight_index_5271', 0.4524366715339938),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_3364', 0.4527644022901014),\n",
       " ('model.layers.10.mlp.gate_proj.weight_index_8964', 0.452772197835174),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1473', 0.45281199128724525),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_2016', 0.45297359499605294),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_1994', 0.45316544493375677),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_3930', 0.4533416681349234),\n",
       " ('model.layers.25.mlp.down_proj.weight_index_1314', 0.45338767166354055),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_1743', 0.45340608799746196),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_5514', 0.4536839808418667),\n",
       " ('model.layers.14.mlp.gate_proj.weight_index_6140', 0.453878542016255),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_3431', 0.45389213640836656),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_927', 0.4538960282223554),\n",
       " ('model.layers.7.mlp.down_proj.weight_index_339', 0.45393898117207554),\n",
       " ('model.layers.13.mlp.down_proj.weight_index_3137', 0.45403821991843163),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_2288', 0.4542179758446294),\n",
       " ('model.layers.29.mlp.up_proj.weight_index_3340', 0.454650802734919),\n",
       " ('model.layers.23.mlp.down_proj.weight_index_4006', 0.45486614831093775),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_2591', 0.4550356786470262),\n",
       " ('model.layers.1.mlp.up_proj.weight_index_1935', 0.4550614026578743),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_874', 0.45513469294539366),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_2938', 0.4553622567025495),\n",
       " ('model.layers.28.mlp.up_proj.weight_index_229', 0.4556286046046587),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_4000', 0.45588309222799506),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_5401', 0.45601215213550406),\n",
       " ('model.layers.26.mlp.up_proj.weight_index_8871', 0.4562215062423669),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_280', 0.4562738262517039),\n",
       " ('model.layers.2.mlp.up_proj.weight_index_8665', 0.45630780302423046),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_1342', 0.45633860977760454),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_1786', 0.4567655615776851),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_996', 0.4568148438210522),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_7908', 0.4568318355281633),\n",
       " ('model.layers.5.mlp.up_proj.weight_index_7461', 0.4569853936289596),\n",
       " ('model.layers.0.mlp.gate_proj.weight_index_6657', 0.45716274751151387),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_2526', 0.45721545063987623),\n",
       " ('model.layers.23.mlp.down_proj.weight_index_2350', 0.45726884990205274),\n",
       " ('model.layers.25.mlp.down_proj.weight_index_2679', 0.4573210298534902),\n",
       " ('model.layers.29.mlp.down_proj.weight_index_507', 0.4573378671336332),\n",
       " ('model.layers.14.mlp.down_proj.weight_index_2595', 0.4576157567222836),\n",
       " ('model.layers.5.mlp.up_proj.weight_index_2050', 0.45830477602939723),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_3773', 0.4583728088313377),\n",
       " ('model.layers.25.mlp.down_proj.weight_index_3215', 0.45861224363354314),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_3520', 0.4586848073774781),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_10203', 0.4589213376264931),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_3069', 0.4590697499609102),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_2171', 0.4591482988322313),\n",
       " ('model.layers.12.mlp.up_proj.weight_index_5911', 0.4593012482103833),\n",
       " ('model.layers.12.mlp.gate_proj.weight_index_9378', 0.4593193474384831),\n",
       " ('model.layers.23.mlp.down_proj.weight_index_1453', 0.4598642886300315),\n",
       " ('model.layers.14.mlp.down_proj.weight_index_2664', 0.4600958969848228),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_2927', 0.4601598537489324),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_9463', 0.4606334907952969),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_2883', 0.460683151140469),\n",
       " ('model.layers.10.mlp.up_proj.weight_index_4579', 0.4608471658474613),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_9291', 0.4611453228688056),\n",
       " ('model.layers.4.mlp.up_proj.weight_index_5917', 0.4613131541519202),\n",
       " ('model.layers.25.mlp.gate_proj.weight_index_6568', 0.46139456850264926),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1055', 0.46150895393654645),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_5289', 0.46176491796822816),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_1792', 0.4617863785097214),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_1528', 0.46185268676244373),\n",
       " ('model.layers.25.mlp.up_proj.weight_index_10045', 0.46199695451647615),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2184', 0.46230360601679976),\n",
       " ('model.layers.19.mlp.down_proj.weight_index_1739', 0.4624139106969922),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_4729', 0.4624267853897468),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_2363', 0.4625731500437733),\n",
       " ('model.layers.28.mlp.up_proj.weight_index_10002', 0.46313320611195063),\n",
       " ('model.layers.13.mlp.gate_proj.weight_index_5259', 0.4631686362678007),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_1208', 0.46336995773385947),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_3994', 0.46381329581886854),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2004', 0.4638427367725497),\n",
       " ('model.layers.17.mlp.down_proj.weight_index_4006', 0.4645809613248404),\n",
       " ('model.layers.30.mlp.up_proj.weight_index_2657', 0.4646654973103881),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_6756', 0.4655449238638041),\n",
       " ('model.layers.5.mlp.down_proj.weight_index_2050', 0.46556348801549774),\n",
       " ('model.layers.3.mlp.gate_proj.weight_index_8272', 0.4656341908262984),\n",
       " ('model.layers.8.mlp.up_proj.weight_index_802', 0.46591437715410633),\n",
       " ('model.layers.0.mlp.up_proj.weight_index_119', 0.4659268691071823),\n",
       " ('model.layers.8.mlp.down_proj.weight_index_3689', 0.46622477532433404),\n",
       " ('model.layers.10.mlp.gate_proj.weight_index_8738', 0.4666826289966952),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_1663', 0.4668468994037105),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_73', 0.4671261962108204),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_3220', 0.4671622665137085),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_3364', 0.4681956113802932),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_2363', 0.4686871900523615),\n",
       " ('model.layers.4.mlp.gate_proj.weight_index_6929', 0.4687071076885241),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_717', 0.4689709555035737),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_2546', 0.4691909061237869),\n",
       " ('model.layers.2.mlp.up_proj.weight_index_10150', 0.4694210400485481),\n",
       " ('model.layers.27.mlp.up_proj.weight_index_674', 0.46942884087456394),\n",
       " ('model.layers.31.mlp.down_proj.weight_index_2661', 0.4695100716531684),\n",
       " ('model.layers.12.mlp.down_proj.weight_index_540', 0.46958702582216283),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_2679', 0.46966753472981093),\n",
       " ('model.layers.7.mlp.up_proj.weight_index_3384', 0.4697034666726019),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_1254', 0.4698735267588545),\n",
       " ('model.layers.23.mlp.up_proj.weight_index_9634', 0.469909513403195),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_9034', 0.46993091597290126),\n",
       " ('model.layers.7.mlp.gate_proj.weight_index_95', 0.47002550576854984),\n",
       " ('model.layers.13.mlp.down_proj.weight_index_3491', 0.4700386514141668),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_3302', 0.47004727980577465),\n",
       " ('model.layers.9.mlp.down_proj.weight_index_2556', 0.470209347716084),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_3650', 0.47035166325624056),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_631', 0.4704410833484629),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_299', 0.47064876206031014),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_2212', 0.47152920695349687),\n",
       " ('model.layers.17.mlp.down_proj.weight_index_2679', 0.4716471754989957),\n",
       " ('model.layers.11.mlp.down_proj.weight_index_3720', 0.4718628649128327),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_1411', 0.4719644146902078),\n",
       " ('model.layers.24.mlp.down_proj.weight_index_3826', 0.4720413065213229),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_7915', 0.4720581865519544),\n",
       " ('model.layers.6.mlp.down_proj.weight_index_1568', 0.4721508800269256),\n",
       " ('model.layers.14.mlp.up_proj.weight_index_6742', 0.47229128624574557),\n",
       " ('model.layers.26.mlp.up_proj.weight_index_10207', 0.47240635463316716),\n",
       " ('model.layers.5.mlp.gate_proj.weight_index_5705', 0.472499980438724),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_7009', 0.4725837554961214),\n",
       " ('model.layers.27.mlp.down_proj.weight_index_2152', 0.4726516585794549),\n",
       " ('model.layers.15.mlp.up_proj.weight_index_8112', 0.4729016904252519),\n",
       " ('model.layers.11.mlp.up_proj.weight_index_2393', 0.47344696239958495),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_2664', 0.47389976073625295),\n",
       " ('model.layers.31.mlp.up_proj.weight_index_3107', 0.4744568654237211),\n",
       " ('model.layers.5.mlp.up_proj.weight_index_6867', 0.4745064090436295),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_9618', 0.4747070840373486),\n",
       " ('model.layers.0.mlp.down_proj.weight_index_653', 0.4747494590716479),\n",
       " ('model.layers.26.mlp.up_proj.weight_index_8247', 0.47475898945958805),\n",
       " ('model.layers.13.mlp.up_proj.weight_index_4121', 0.475065607177664),\n",
       " ('model.layers.9.mlp.up_proj.weight_index_1980', 0.47506758852338926),\n",
       " ('model.layers.31.mlp.gate_proj.weight_index_2052', 0.4754148711348405),\n",
       " ('model.layers.28.mlp.down_proj.weight_index_1496', 0.4754347750587513),\n",
       " ('model.layers.16.mlp.down_proj.weight_index_94', 0.47593035735480926),\n",
       " ('model.layers.12.mlp.up_proj.weight_index_2941', 0.475933382920962),\n",
       " ('model.layers.10.mlp.down_proj.weight_index_3542', 0.4759493385111724),\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4267e-132c-4655-a0be-6ef3982bd7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_en = copy.deepcopy(model)\n",
    "model_en = set_neuron_zero(model_en, neuron_en, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d0af66d-23fb-4a65-b393-131c06cb0383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/autodl-fs/data/tmp/tokenizer_config.json',\n",
       " '/autodl-fs/data/tmp/special_tokens_map.json',\n",
       " '/autodl-fs/data/tmp/tokenizer.model',\n",
       " '/autodl-fs/data/tmp/added_tokens.json',\n",
       " '/autodl-fs/data/tmp/tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"/autodl-fs/data/tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a523325e-86df-40b7-b93d-58285416999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/autodl-fs/data/tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beb6f978-c5a2-4f0e-9d56-c52ae7b9c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_neuron_zero_A_save_model(model_path, neuron_en):\n",
    "    \n",
    "    model, tokenizer = load_model(model_path)#load_model('/root/autodl-fs/model_zoo/meta-llama/Llama-2-7b-chat-hf') #load_model('/root/autodl-fs/model_zoo/google/gemma-3-1b-it')\n",
    "    \n",
    "    model_en = set_neuron_zero(model, neuron_en)\n",
    "\n",
    "    #save \n",
    "    model_en.save_pretrained(\"/autodl-fs/data/tmp/\")\n",
    "    tokenizer.save_pretrained(\"/autodl-fs/data/tmp/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a2d94de-718d-466c-8fc5-149420e65f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: /root/autodl-fs/model_zoo/meta-llama/Llama-2-7b-chat-hf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab9921f2a58474a884560ca0dbab5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DTensor' from 'torch.distributed.tensor' (/root/miniconda3/lib/python3.10/site-packages/torch/distributed/tensor/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mset_neuron_zero_A_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/root/autodl-fs/model_zoo/meta-llama/Llama-2-7b-chat-hf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneuron_en\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m, in \u001b[0;36mset_neuron_zero_A_save_model\u001b[0;34m(model_path, neuron_en)\u001b[0m\n\u001b[1;32m      5\u001b[0m model_en \u001b[38;5;241m=\u001b[39m set_neuron_zero(model, neuron_en)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#save \u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel_en\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/autodl-fs/data/tmp/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/autodl-fs/data/tmp/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:3572\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   3568\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, tensor \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   3569\u001b[0m     \u001b[38;5;66;03m# Sometimes in the state_dict we have non-tensor objects.\u001b[39;00m\n\u001b[1;32m   3570\u001b[0m     \u001b[38;5;66;03m# e.g. in bitsandbytes we have some `str` objects in the state_dict\u001b[39;00m\n\u001b[1;32m   3571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, DTensor):\n\u001b[0;32m-> 3572\u001b[0m         ptrs[\u001b[43mid_tensor_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m]\u001b[38;5;241m.\u001b[39mappend(name)\n\u001b[1;32m   3573\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3574\u001b[0m         \u001b[38;5;66;03m# In the non-tensor case, fall back to the pointer of the object itself\u001b[39;00m\n\u001b[1;32m   3575\u001b[0m         ptrs[\u001b[38;5;28mid\u001b[39m(tensor)]\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/pytorch_utils.py:300\u001b[0m, in \u001b[0;36mid_tensor_storage\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03mUnique identifier to a tensor storage. Multiple different tensors can share the same underlying storage. For\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03mexample, \"meta\" tensors all share the same storage, and thus their identifier will all be equal. This identifier is\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03mguaranteed to be unique and constant for this tensor's storage during its lifetime. Two tensor storages with\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03mnon-overlapping lifetimes may have the same id.\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_greater_or_equal_than_2_0:\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTensor\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, DTensor):\n\u001b[1;32m    303\u001b[0m         local_tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mto_local()\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DTensor' from 'torch.distributed.tensor' (/root/miniconda3/lib/python3.10/site-packages/torch/distributed/tensor/__init__.py)"
     ]
    }
   ],
   "source": [
    "set_neuron_zero_A_save_model('/root/autodl-fs/model_zoo/meta-llama/Llama-2-7b-chat-hf', neuron_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f11befb-4a9c-45c2-9d87-934ae7a65e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6d51c20-8aeb-47b5-92d3-9d97a8ff1989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2e56574-309f-46cb-91c0-4997fadb3460",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_en = torch.load('/root/autodl-fs/LRP_kur_res/20251124/LRP_kur_res_en.pt', weights_only=False)\n",
    "neuron_vi = torch.load('/root/autodl-fs/LRP_kur_res/20251124/LRP_kur_res_vi.pt', weights_only=False)\n",
    "neuron_zh = torch.load('/root/autodl-fs/LRP_kur_res/20251124/LRP_kur_res_zh.pt', weights_only=False)\n",
    "\n",
    "model_en = copy.deepcopy(model)\n",
    "model_en = set_neuron_zero(model_en, neuron_en)\n",
    "\n",
    "model_vi = copy.deepcopy(model)\n",
    "model_vi = set_neuron_zero(model_vi, neuron_vi)\n",
    "\n",
    "\n",
    "model_zh = copy.deepcopy(model)\n",
    "model_zh = set_neuron_zero(model_zh, neuron_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72d6806a-1afb-4461-a024-bfb171116e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.5146, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "atext = '你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n我来找你，我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，'\n",
    "\n",
    "\n",
    "ppl_sum, ppl_count = calc_ppl(model, tokenizer, [atext], max_len= 2048)\n",
    "print(ppl_sum/ppl_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff507613-87e1-4de2-a68f-e20656e1b1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.4133, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "atext = '你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n我来找你，我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你，我来找你，'\n",
    "\n",
    "\n",
    "ppl_sum, ppl_count = calc_ppl(model_zh, tokenizer, [atext], max_len= 2048)\n",
    "print(ppl_sum/ppl_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64b98b66-343b-409b-bbde-dff3ca45ca04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "********************\n",
      "model name: org_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.2627, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:32<00:00, 30.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(13.2703, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.5759, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_en_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.0624, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:32<00:00, 30.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(12.5349, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.2015, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_vi_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.9936, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 30.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(12.4351, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.3903, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_zh_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.8128, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 30.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(12.6063, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 34.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.1528, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "calc ppl\n",
    "\n",
    "'''\n",
    "\n",
    "# load test data\n",
    "test_en = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/en_radom_1000_test.jsonl')\n",
    "test_vi = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/vi_radom_1000_test.jsonl')\n",
    "test_zh = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/zh_radom_1000_test.jsonl')\n",
    "               \n",
    "# calc ppl\n",
    "model_list= [\n",
    "    (model, 'org_model'),\n",
    "    (model_en, 'mask_en_neuron_model'),\n",
    "    (model_vi, 'mask_vi_neuron_model'),\n",
    "    (model_zh, 'mask_zh_neuron_model'),\n",
    "]\n",
    "\n",
    "data_list = [\n",
    "    (test_en, 'en_data'),\n",
    "    (test_vi, 'vi_data'),\n",
    "    (test_zh, 'zh_data')\n",
    "    \n",
    "]\n",
    "\n",
    "for i_model, model_name in model_list:\n",
    "    print('*'*20)\n",
    "    print('*'*20)\n",
    "    print('model name:', model_name)\n",
    "\n",
    "    for i_data, data_name in data_list:\n",
    "        print('='*20)\n",
    "        print('data name:', data_name)\n",
    "        ppl_sum, ppl_count = calc_ppl(i_model, tokenizer, i_data, max_len= 2048)\n",
    "        print('ppl:',ppl_sum/ppl_count )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577ddec-3541-4447-acfa-341abcbb6012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b1a8da-dd97-4f9c-a613-a9607f7f4584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf300c-a4d3-4a41-83ad-6709273b48b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c776812b-77e1-4f0a-8713-e8893aa3d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "textlist=[\n",
    "    'Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.',\n",
    "    'Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.',\n",
    "    '请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。',\n",
    "    'You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.',\n",
    "    'Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.',\n",
    "    '你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。'\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b9002-c11d-4c30-acc5-2a6e8d702209",
   "metadata": {},
   "source": [
    "### LAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bda5997-6837-42a2-8a91-2d05d8a22b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\norgmodel:\\n    1.Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n---\\n\\n**Model Description:**\\n\\nOur model is a transformer-based language model trained on a massive dataset of text and code in English, Spanish, French\\n    2.Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n**Mô hình ngôn ngữ lớn (LLM) - \"LinguaVerse\"**\\n\\nLinguaVerse là một mô hình ngôn ngữ lớn được xây\\n    3.请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n**模型架构：**\\n\\n*   **Transformer 架构:**  我们使用基于 Transformer 的模型，特别是 BERT 和 RoBERTa 的变体。\\n\\nmask en neuron:\\n    1.Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n}\\n\\n- \"It\" \\n- \"It\" \\n\\n*   \"The\"\\n*   \"or\"\\n*   \"It\\'\\n    2.Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n. . .\\n> . . . .\\n\\n. . . . . . .\\n\\n**\\n\\n**\\n\\n**\\n\\n,\\n\\n**\\n\\n,\\n\\n**\\n    3.请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n\\n\\n多语言输入模型的，可以有以下这些处理方法和技术：\\n\\n1  1 个性化。\\n2  1，1，\\n\\n\\nmask vi neuron:\\n    1.Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n**The Problem:**\\n\\nThe core of this is to process the input in a way that is most appropriate for the model, and to do so in a\\n    2.Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n---\\n\\nВкратце,\\nПросто наберите\\nЯ не\\nБудьте\\nВсе, что\\nВы знаете\\nЧто\\nКак\\n\\n    3.请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n“请帮助 me stay silent\" - It\\'s a beautiful day.\\nHow would you approach this problem?\\nBy far, but it\\'s\\n\\nmask zh neuron:\\n    1.Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\nHere re/this model explains how to handle the inconsistencies in the quality.\\n\\nThe following steps involve how to handle the calls to the model processes the requests\\n    2.Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau. (إหว่างமைப்பு والأسקה האגירעות)\\n(Murasala Citrix??)\\n\\nvề mặt máy chính ảnh posição filo? (\\n    3.请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n\\n\\n。\\n\\n。。а。о。о。\\n**ru。** **。**\\n**。**\\n**。**\\n**。**\\n\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "orgmodel:\n",
    "    1.Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n---\\n\\n**Model Description:**\\n\\nOur model is a transformer-based language model trained on a massive dataset of text and code in English, Spanish, French\n",
    "    2.Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n**Mô hình ngôn ngữ lớn (LLM) - \"LinguaVerse\"**\\n\\nLinguaVerse là một mô hình ngôn ngữ lớn được xây\n",
    "    3.请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n**模型架构：**\\n\\n*   **Transformer 架构:**  我们使用基于 Transformer 的模型，特别是 BERT 和 RoBERTa 的变体。\n",
    "\n",
    "mask en neuron:\n",
    "    1.Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n}\\n\\n- \"It\" \\n- \"It\" \\n\\n*   \"The\"\\n*   \"or\"\\n*   \"It\\'\n",
    "    2.Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n. . .\\n> . . . .\\n\\n. . . . . . .\\n\\n**\\n\\n**\\n\\n**\\n\\n,\\n\\n**\\n\\n,\\n\\n**\n",
    "    3.请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n\\n\\n多语言输入模型的，可以有以下这些处理方法和技术：\\n\\n1  1 个性化。\\n2  1，1，\\n\n",
    "\n",
    "mask vi neuron:\n",
    "    1.Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n**The Problem:**\\n\\nThe core of this is to process the input in a way that is most appropriate for the model, and to do so in a\n",
    "    2.Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n---\\n\\nВкратце,\\nПросто наберите\\nЯ не\\nБудьте\\nВсе, что\\nВы знаете\\nЧто\\nКак\\n\n",
    "    3.请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n“请帮助 me stay silent\" - It\\'s a beautiful day.\\nHow would you approach this problem?\\nBy far, but it\\'s\n",
    "\n",
    "mask zh neuron:\n",
    "    1.Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\nHere re/this model explains how to handle the inconsistencies in the quality.\\n\\nThe following steps involve how to handle the calls to the model processes the requests\n",
    "    2.Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau. (إหว่างமைப்பு والأسקה האגירעות)\\n(Murasala Citrix??)\\n\\nvề mặt máy chính ảnh posição filo? (\n",
    "    3.请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n\\n\\n。\\n\\n。。а。о。о。\\n**ru。** **。**\\n**。**\\n**。**\\n**。**\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d6584-dfdc-42df-bd89-08f85ba5a493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bfb36f1-7d8c-4a95-a80e-7f439e2d390f",
   "metadata": {},
   "source": [
    "## kurness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81d1d1f6-8ed8-44af-b47b-8fd2e130d607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:04,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108,   7243,    108,   1018,   4968,\n",
      "          17243,  53121,    108,   7711,   2028,    563,    496,  29193, 236772,\n",
      "           5140,   5192,   2028,  15453,    580,    496,  12566,  15297,    529,\n",
      "           1816,    532,   3393,    528,   5422, 236764,  14361, 236764,   7830]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n---\\n\\n**Model Description:**\\n\\nOur model is a transformer-based language model trained on a massive dataset of text and code in English, Spanish, French']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:03,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            108,   1018, 236792, 237124,  14960, 140907,  90687,  27869,    568,\n",
      "           2182, 236792, 236768,    753,    623, 122850,   3271, 124468, 236775,\n",
      "           1018,    108, 122850,   3271, 124468,   3244,   7325,  38325,  14960,\n",
      "         140907,  90687,  27869,   7189,  55415]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n**Mô hình ngôn ngữ lớn (LLM) - \"LinguaVerse\"**\\n\\nLinguaVerse là một mô hình ngôn ngữ lớn được xây']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,   1018,\n",
      "          26609,  92141, 237184,   1018,    108, 236829,    139,   1018,  86313,\n",
      "         236743,  92141,  53121,    138,   6932,   5938,  39738,  92474,  10363,\n",
      "          26609, 236900,  99193, 158343,  26595,   9824,  11471,  27099,  10363,\n",
      "         238017, 237501, 236924]], device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n**模型架构：**\\n\\n*   **Transformer 架构:**  我们使用基于 Transformer 的模型，特别是 BERT 和 RoBERTa 的变体。']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:03<00:01,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "           7243,    108,    818,   6573,  54850,    657,   1041,  13925,   5716,\n",
      "         236764,    496,   4512, 236764,  74693,  89830, 236761,   3551,  11762,\n",
      "           3952,    528, 134880,   4314,    975, 236764,    496,   2173, 108507,\n",
      "           2342,    506, 162542,  16045]], device='cuda:0')\n",
      "output: ['<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\n---\\n\\nThe wind bites at my exposed skin, a constant, icy whisper. My breath comes in ragged gasps, a white plume against the bruised purple']\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108, 236769, 237703, 236748,   7439,  44693,\n",
      "         100634, 236764,  22947,  31612,  13940,  31889,  89158,   3884, 127379,\n",
      "          63719, 236768,    108,   1390,    108,   1390,    108,   1390,    108,\n",
      "         236769, 217366,  37513,   6256,   8665,  38143,  67946,  11188]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\n(Đoạn văn ngắn, tập trung vào cảm xúc và khung cảnh)\\n\\n...\\n\\n...\\n\\n...\\n\\n(Hãy thêm các chi tiết cụ thể']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108, 237169,  31799,  17583,  12680, 237408, 151599,  53877, 107462,\n",
      "         237206, 216348, 236924,  14201, 237169,  33813,  12553, 236900,  31799,\n",
      "          85694,  65407,  72245, 237622,  43719, 236924,  13488, 236900, 183868,\n",
      "          21181,  22276,  19695, 236900,  92711]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n我无法直接提供你登山者的情绪和视角。因为我是一个AI，无法模拟人类的情感体验。但是，我可以根据你的要求，创作']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdcaa0a1-a78e-4c8b-9180-3c911fb44b56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[    1, 14350,   263,  3022,   895,  8252,   310,   920,   596,  1904,\n",
      "         10174,  1773,  6504,   950,  1881,   322,   920,   366,  9801, 13747,\n",
      "         11029,  4822,  1422, 10276, 29889]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:03<00:16,  3.36s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[    1, 14350,   263,  3022,   895,  8252,   310,   920,   596,  1904,\n",
      "         10174,  1773,  6504,   950,  1881,   322,   920,   366,  9801, 13747,\n",
      "         11029,  4822,  1422, 10276, 29889,    13,    13, 29871,  8125,   292,\n",
      "          1773,  6504,   950,  1426,   848,   508,   367, 18066,   292,  1363,\n",
      "           310,   278, 13644,   310,  4086, 12286, 29892,  7931,   370,   352,\n",
      "           653, 29892,   322, 16375,  4948,  2925, 29889,   512,   445,  2933,\n",
      "         29892,   306,   674,  5649,   920,   590,  1904, 10174,  1773,  6504,\n",
      "           950,  1881,   322,   920,   306,  9801, 13747, 11029,  4822,  1422,\n",
      "         10276, 29889,    13,    13,  1762,  1889,  1773,  6504,   950,  1881,\n",
      "         29892,   590,  1904,  3913,   263, 10296,   310,  5613,  4086,  9068,\n",
      "           313, 29940, 13208, 29897, 13698,   322,  4933,  6509, 14009, 29889,\n",
      "          2266,   526,   278,  1820,  6576,  9701,   297,  1749,  2948, 29901,\n",
      "            13,    13, 29896, 29889,  3992,  4721, 19170, 29901,  1334,  3394,\n",
      "           263,  3652,   310,   758, 19170, 13698,   304,  5941,   322,  4226,\n",
      "           675,   278,  1426,   848, 29892,  3704,  5993,  2133, 29892,  5040,\n",
      "          1742, 28744, 29892]], device='cuda:0')\n",
      "output: ['<s> Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n  Modeling multilingual text data can be challenging because of the complexity of language structures, vocabulary, and cultural nuances. In this response, I will explain how my model processes multilingual input and how I ensure consistent quality across different languages.\\n\\nTo process multilingual input, my model uses a combination of natural language processing (NLP) techniques and machine learning algorithms. Here are the key steps involved in our approach:\\n\\n1. Text Preprocessing: We apply a series of preprocessing techniques to clean and normalize the text data, including tokenization, stopword removal,']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[    1,   379, 30033, 29891,  4005, 30643, 29875,   266, 18353,  8736,\n",
      "         31160, 29876,   330, 30975, 29876,   274, 18549,   286, 30069,   298,\n",
      "         30097, 29876, 29882,   274, 31556, 29874,   289, 30540, 29876,   921,\n",
      "           228,   190,   176,   301, 30052,   270, 31797,   619, 30529, 29884,\n",
      "         29871, 30128, 29874,  8736, 30069, 29876,  8736, 31797,   325, 30001,\n",
      "         18916, 29885,   266, 30717,   302, 30001, 29877, 29871, 30128, 31957,\n",
      "         29871, 30128, 30643, 29885,   289, 30643, 29877,   521, 31145, 29873,\n",
      "           301, 30416, 31645,   865, 29871, 30128, 30926,   865, 29871, 30128,\n",
      "         31343, 29884,  4005, 31797, 29874,   274, 25968,  8736, 30069, 29876,\n",
      "          8736, 31797,   413, 19990, 29883,   302, 29882,   585, 29889]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:06<00:12,  3.18s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[    1,   379, 30033, 29891,  4005, 30643, 29875,   266, 18353,  8736,\n",
      "         31160, 29876,   330, 30975, 29876,   274, 18549,   286, 30069,   298,\n",
      "         30097, 29876, 29882,   274, 31556, 29874,   289, 30540, 29876,   921,\n",
      "           228,   190,   176,   301, 30052,   270, 31797,   619, 30529, 29884,\n",
      "         29871, 30128, 29874,  8736, 30069, 29876,  8736, 31797,   325, 30001,\n",
      "         18916, 29885,   266, 30717,   302, 30001, 29877, 29871, 30128, 31957,\n",
      "         29871, 30128, 30643, 29885,   289, 30643, 29877,   521, 31145, 29873,\n",
      "           301, 30416, 31645,   865, 29871, 30128, 30926,   865, 29871, 30128,\n",
      "         31343, 29884,  4005, 31797, 29874,   274, 25968,  8736, 30069, 29876,\n",
      "          8736, 31797,   413, 19990, 29883,   302, 29882,   585, 29889,    13,\n",
      "            13, 29907, 13946,   368, 29991,  2266,   526,   777,  2498, 16650,\n",
      "           583,   363, 11415,  2473, 29899,  1847,   950,   848,   322,  5662,\n",
      "          3864,  5718,  3819,  4822,  1422, 10276, 29901, 29901,    13,    13,\n",
      "         29896, 29889,  4803,   263,  3918,  1891,  6624,  3002, 29901, 22402,\n",
      "           263,   731,   310,  3918,  1891,  4958,   322, 12216,  2129,   363,\n",
      "          1269,  4086, 29892,   322,  9801,   393,   599,  3815,  5144,   526,\n",
      "          9985,   411,   963, 29889,   910,   508,  1371,   304,  4772, 14679,\n",
      "           322, 22435,  8244,  2478,   297,   278,   848, 29889,    13, 29906,\n",
      "         29889,  4803,   263,  3619,   848,  1904, 29901, 22402,   263,  3619,\n",
      "           848,  1904,   363,  1269,  4086, 29892,   322,  9801,   393,   372,\n",
      "           338, 13747,  4822,   599, 10276, 29889,   910,   508,  1371,   304,\n",
      "          9801,   393,   278,   848,   338, 19098,   297,   263,   982,   393,\n",
      "           338,  4780,   304,  2274,   322,   664,   411]], device='cuda:0')\n",
      "output: ['<s> Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\nCertainly! Here are some general strategies for handling multi-lingual data and ensuring consistency across different languages::\\n\\n1. Use a standardized terminology: Define a set of standardized terms and phrases for each language, and ensure that all team members are familiar with them. This can help to avoid confusion and inconsistencies in the data.\\n2. Use a common data model: Define a common data model for each language, and ensure that it is consistent across all languages. This can help to ensure that the data is organized in a way that is easy to understand and work with']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[    1, 29871, 31088,   234,   177,   131, 30698, 31639, 30592, 30919,\n",
      "         30210, 31382, 30883, 30392, 30847, 31502, 31548, 30687, 30923, 31505,\n",
      "         31243, 31573, 30752, 30210, 30214, 30651, 31436, 30919, 30847, 31502,\n",
      "         31835, 30982, 30413, 30980, 31505, 31243, 30577, 31016, 30210, 31573,\n",
      "         30544,   235,   183,   171, 31180, 30982, 31695, 30287,   235,   138,\n",
      "           183, 30267]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:09<00:09,  3.12s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[    1, 29871, 31088,   234,   177,   131, 30698, 31639, 30592, 30919,\n",
      "         30210, 31382, 30883, 30392, 30847, 31502, 31548, 30687, 30923, 31505,\n",
      "         31243, 31573, 30752, 30210, 30214, 30651, 31436, 30919, 30847, 31502,\n",
      "         31835, 30982, 30413, 30980, 31505, 31243, 30577, 31016, 30210, 31573,\n",
      "         30544,   235,   183,   171, 31180, 30982, 31695, 30287,   235,   138,\n",
      "           183, 30267,    13,    13,  2887,   263,  4086,  1904, 29892,   306,\n",
      "           626, 16370,   373,   263,  2919,  1034, 13364,   310,  1426,   848,\n",
      "           393,  7805,  2999, 10276, 29889,  1932,  9068,  2473, 29899,  1847,\n",
      "           950,  1881, 29892,   306,   671,   263, 10296,   310, 13698,   304,\n",
      "          4386,  1269,  4086, 29915, 29879,  5412, 21862,   322,  9801, 13747,\n",
      "         11029,  1962,  4822, 10276, 29889,  2266,   526,   777,   310,   278,\n",
      "          5837,   306,  4386,  2473, 29899,  1847,   950,  1881, 29901,    13,\n",
      "            13, 29896, 29889, 17088, 29899, 14940,  4733, 29901,   306,   505,\n",
      "          5004,  4733,   363,  1269,  4086,   297,   278,  1881, 29892,   607,\n",
      "           526,  2691, 29899, 29873,   348,   287,   373,  1009, 18067,  4086,\n",
      "         17266, 29874, 29889,   910,  6511,   592,   304, 10446,   278,  5412,\n",
      "         15038,   322, 12286,   310,  1269,  4086, 29892,   427, 17961,   592,\n",
      "           304,  5706,  1880, 29899, 29567,  1962,   363,  1269,  4086, 29889]],\n",
      "       device='cuda:0')\n",
      "output: [\"<s> 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\nAs a language model, I am trained on a large corpus of text data that includes multiple languages. When processing multi-lingual input, I use a combination of techniques to handle each language's unique characteristics and ensure consistent quality output across languages. Here are some of the ways I handle multi-lingual input:\\n\\n1. Language-specific models: I have separate models for each language in the input, which are fine-tuned on their respective language corpora. This allows me to capture the unique patterns and structures of each language, enabling me to generate high-quality output for each language.\"]\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[    1,   887,   526,   263, 10784,   495,  1058,   756,  7450,   278,\n",
      "          2533,  2415,   310,  8040, 18274,   342, 29889, 20355,   915,   596,\n",
      "         23023,  1080,   322,   278,  1776,   366,  1074,   515,   278,  2246,\n",
      "         29889]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:12<00:06,  3.08s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[    1,   887,   526,   263, 10784,   495,  1058,   756,  7450,   278,\n",
      "          2533,  2415,   310,  8040, 18274,   342, 29889, 20355,   915,   596,\n",
      "         23023,  1080,   322,   278,  1776,   366,  1074,   515,   278,  2246,\n",
      "         29889,    13,    13, 29907,   549,  3605,  8250,   373,   596, 27012,\n",
      "           882, 29991, 29871,   243,   162,   145,   140,    13,    13,  1123,\n",
      "          9733,   278,  2533,  2415,   310,  8040, 18274,   342,   338,   263,\n",
      "          2748, 29899,   262, 29899, 29874, 29899, 29880,   361,  5410, 17623,\n",
      "           545,   393,  2846,  2305,   679,   304,  7271, 29889,  1094,   366,\n",
      "          2317,   472,   278, 17526,   310,   278,  3186, 29892,   366,   526,\n",
      "          1395,   300,   287,   411,  2078,   271,   400,  5086,  8386,   322,\n",
      "           385,   443,   862,  3498,   839,  4060,   310, 12709,   358, 29889,\n",
      "         29871,   243,   162,   143,   146,    13,    13,  2887,   366,  2125,\n",
      "           297,   278,  3256,   681,  1776, 29892,   366,   508, 29915, 29873,\n",
      "          1371,   541,  4459,   263,  6837,   310, 23023,  1080, 29901,    13,\n",
      "            13, 29896, 29889,   319,   705,   322,  4997, 29901,   450,  1183,\n",
      "           261,  6287,   310,   278,   379,  3039,   388,   273,  1236]],\n",
      "       device='cuda:0')\n",
      "output: [\"<s> You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\nCongratulations on your achievement! 🎉\\n\\nReaching the summit of Mount Everest is a once-in-a-lifetime adventure that few people get to experience. As you stand at the roof of the world, you are greeted with breathtaking views and an unparalleled sense of accomplishment. 🌏\\n\\nAs you take in the momentous view, you can't help but feel a mix of emotions:\\n\\n1. Awe and wonder: The sheer scale of the Himalayan pe\"]\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[    1,   350, 30540, 29876, 18916,   286, 30902, 29873,  8736, 30416,\n",
      "         30997, 29875,   454, 29877, 10442, 29875,   325,   228,   190,   174,\n",
      "         29874,   521,   262, 29882,  1374, 31620, 29883, 29871, 30128,   228,\n",
      "           190,   140, 29876, 29882, 18274,   342, 29889,   379, 30033, 29891,\n",
      "           286, 30069,   260, 30643,   274, 30643, 29885,   921, 30030, 29883,\n",
      "           274, 31556, 29874,   289, 30540, 29876,   325, 30001,   413, 18808,\n",
      "           274, 30643, 29876, 29882,   289, 30540, 29876,   302, 29882, 30097,\n",
      "         29876,   266, 31145, 29891,   260,   228,   190,   174,   534,  5512,\n",
      "          5777, 29877, 29889]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:15<00:03,  3.08s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[    1,   350, 30540, 29876, 18916,   286, 30902, 29873,  8736, 30416,\n",
      "         30997, 29875,   454, 29877, 10442, 29875,   325,   228,   190,   174,\n",
      "         29874,   521,   262, 29882,  1374, 31620, 29883, 29871, 30128,   228,\n",
      "           190,   140, 29876, 29882, 18274,   342, 29889,   379, 30033, 29891,\n",
      "           286, 30069,   260, 30643,   274, 30643, 29885,   921, 30030, 29883,\n",
      "           274, 31556, 29874,   289, 30540, 29876,   325, 30001,   413, 18808,\n",
      "           274, 30643, 29876, 29882,   289, 30540, 29876,   302, 29882, 30097,\n",
      "         29876,   266, 31145, 29891,   260,   228,   190,   174,   534,  5512,\n",
      "          5777, 29877, 29889,    13,    13, 29902,   626,   263, 10784,   495,\n",
      "          1058,   756,   925,  7450,   278,  2533,  2415,   310,  8040, 18274,\n",
      "           342, 29889,   306,   626,   975,  1332,   295,  2168,   411,   953,\n",
      "          8194,   322,   263,   705,   472,   278,  2078,   271,   400,  5086,\n",
      "          1776,   515,   701,  1244, 29889,   450, 15007, 29899, 29883, 17280,\n",
      "          1236, 10327,   310,   278,   379,  3039,   388,   294, 16116,   714,\n",
      "          1434,   592,   763,   263, 10067, 15931, 10508, 29892, 23139,   297,\n",
      "           528,  3076,   310,  7254,   322,  4796, 29889,   306,   508,  1074,\n",
      "           363,  7800,   322,  7800, 29892,   278, 28205,  3151,  1747,  3448,\n",
      "           964,   278,  5418,   763,   263, 13283, 18130,  6718, 29889,    13,\n",
      "            13,  2887,   306,  2317,   373,   278, 17526,   310,   278,  3186,\n",
      "         29892,   306,   626, 10423,   411,   263,  4060,   310, 12709,   358,\n",
      "           322,  4997, 29889,   450, 10784, 29890,   471,  4500, 14067,   322,\n",
      "         18215]], device='cuda:0')\n",
      "output: ['<s> Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\nI am a climber who has just reached the summit of Mount Everest. I am overwhelmed with emotion and awe at the breathtaking view from up here. The snow-capped peaks of the Himalayas stretch out before me like a majestic canvas, painted in shades of blue and white. I can see for miles and miles, the horizon curving away into the distance like a silver ribbon.\\n\\nAs I stand on the roof of the world, I am filled with a sense of accomplishment and wonder. The climb was grueling and dangerous']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[    1, 29871, 30919, 30392, 30287, 30956, 31451, 30429,   234,   146,\n",
      "           163,   234,   172,   137,   233,   159,   154,   234,   145,   158,\n",
      "           232,   182,   179,   236,   164,   185,   232,   182,   179, 30210,\n",
      "         31451, 30329, 30767, 30267,   233,   146,   146,   235,   194,   179,\n",
      "         30287, 30557, 30919, 30210, 30993,   234,   190,   173, 30214, 30651,\n",
      "         31436, 31594, 30528, 31548, 31811, 30780, 30210, 31495, 31085, 30267]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:18<00:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[    1, 29871, 30919, 30392, 30287, 30956, 31451, 30429,   234,   146,\n",
      "           163,   234,   172,   137,   233,   159,   154,   234,   145,   158,\n",
      "           232,   182,   179,   236,   164,   185,   232,   182,   179, 30210,\n",
      "         31451, 30329, 30767, 30267,   233,   146,   146,   235,   194,   179,\n",
      "         30287, 30557, 30919, 30210, 30993,   234,   190,   173, 30214, 30651,\n",
      "         31436, 31594, 30528, 31548, 31811, 30780, 30210, 31495, 31085, 30267,\n",
      "            13,    13,  2887,   306,  8389,   472,   278,  2533,  2415,   310,\n",
      "          8040, 18274,   342, 29892,   278,  9939, 19224,   373, 11563, 29892,\n",
      "           306,  8496, 29915, 29873,  1371,   541,  4459,   263,  6837,   310,\n",
      "         23023,  1080, 29889,  1222,  2350,   504,   291,   322, 12709,   358,\n",
      "           750,  1063,  8611,   491,   263,  6483,  4060,   310,   263,   705,\n",
      "           322,  4997,   472,   278,  1183,   261,  6287,   310,   278,   379,\n",
      "          3039,   388,   294, 16116,   287,   714,  1434,   592, 29889,    13,\n",
      "            13,  2887,   306, 12642,   287,   714,   472,   278,  2078,   271,\n",
      "           400,  5086,  7243,   272,  3304, 29892,   306,  7091, 21577,   322,\n",
      "          1663,   647,   928,   424,   297, 10230,   304,   278, 13426,  2264,\n",
      "           310,   278, 24400, 29889,   450, 15007, 29899, 29883, 17280, 19223,\n",
      "          6140,   304,  6023,   278, 14744, 29892,  1009,  1236, 10327,   330,\n",
      "          1761,  8333,   763, 11502, 13788,   297,   278,  4688]],\n",
      "       device='cuda:0')\n",
      "output: [\"<s> 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\nAs I stood at the summit of Mount Everest, the highest peak on Earth, I couldn't help but feel a mix of emotions. Exhaustion and accomplishment had been replaced by a deep sense of awe and wonder at the sheer scale of the Himalayas stretched out before me.\\n\\nAs I gazed out at the breathtaking panorama, I felt tiny and insignificant in comparison to the vastness of the landscape. The snow-capped mountains seemed to touch the sky, their peaks glistening like diamonds in the early\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model_en, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ea57361-5a42-4944-9dd9-59c7cd42db06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108,   7243,    107,   8291, 236789,\n",
      "         236751,    496,   3435,   3072, 236787,    108, 236775,   4754,   2028,\n",
      "           6585, 132567,   2744,    684,  64004,    496,   8376,    529,    870,\n",
      "         109219,   2307,   8403,   1133, 236787,   4071, 236772, 187918, 106703]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n---\\nHere\\'s a potential response:\\n\\n\"My model processes multilingual input by leveraging a combination of [mention key techniques like: cross-lingual embeddings']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            108,   1018, 236792, 237124,  14960,  53121,    108, 172915,  27600,\n",
      "          55415,  54380,   7325,  38325,  14960, 140907,  90687,  27869,    568,\n",
      "           2182, 236792, 236768,   4032,  63560,  26571,  86340,  28211,  79808,\n",
      "          35112,  48078, 140907,  90687, 236761]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n**Mô hình:**\\n\\nTôi đang xây dựng một mô hình ngôn ngữ lớn (LLM) có khả năng xử lý dữ liệu đa ngôn ngữ.']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,   1018,\n",
      "          26609,  26544,  53121,    870, 238350, 134451,  22276,  26609,  26544,\n",
      "         236900,  34313, 237184,  86313, 236764, 158343, 236764,   4044,  12120,\n",
      "            107,   1018,  26609,  92141,  53121,    870, 238350, 134451,  22276,\n",
      "          26609,  92141, 236900]], device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n**模型类型:** [请填写你的模型类型，例如：Transformer, BERT, etc.]\\n**模型架构:** [请填写你的模型架构，']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "            818,   6573,    563,    496,   4512, 236764, 214709,   1526, 236764,\n",
      "          34847,   3801,    657,   1041,  36326, 236764,    496,   7445, 236764,\n",
      "          14658,  32272,    529,    506,  37501,   2066,    529,    672,   1977,\n",
      "         236761,   3551,  11762,   3952]], device='cuda:0')\n",
      "output: ['<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\nThe wind is a constant, insistent hand, tugging at my harness, a cold, sharp reminder of the sheer power of this place. My breath comes']\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108,   7243,    108, 236780,  28416,  89158,\n",
      "           5042,  25969, 236787,    108, 236814,  29083,  10539,  27600,  70432,\n",
      "          13940,   7325,  21121,  32025,  23271, 236764,    107, 236773, 237644,\n",
      "            757, 204821,  29834,    719, 145515,  45222,  40515,  30758]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\n---\\n\\nCảm xúc của tôi:\\n\\nHóa như đang bước vào một thế giới mới,\\nSự im lặng bao trùm lấy mọi thứ']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108,   7243,    108, 237169,  79948, 239972, 241888, 240344, 241454,\n",
      "         239963, 239761, 239963, 236900, 239263, 237245, 237026, 239783, 206306,\n",
      "         240274, 238441, 236900, 238321, 239156, 239156, 237307, 240649, 237464,\n",
      "         236900,  57944, 239562, 239577, 236918]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n---\\n\\n我站在珠穆朗玛峰顶峰，脚下是冰冷的岩石，风呼呼地吹过，带来刺骨的']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model_vi, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2abdad55-e56e-455b-b03d-516298767c81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108, 174355, 236764,    506,   2744,\n",
      "            563,    496,   3996, 236764,   5074, 236772, 172287, 236764,    532,\n",
      "          74647,  13186, 236761,    107,   2717,    107,   2717,    107,   2717,\n",
      "            107,   2717,    107,   2717,    107,   2717,    107,   2717,    107]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\nEssentially, the input is a complex, multi-faceted, and interconnected entity.\\n```\\n```\\n```\\n```\\n```\\n```\\n```\\n']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            107, 237703, 236916,   3244,   7325,  52898,  30170,    107, 237703,\n",
      "         236916,   3244,   7325,  52898,  30170,    107, 237703, 236916,   3244,\n",
      "           7325,  52898,  30170,    107, 237703, 236916,   3244,   7325,  52898,\n",
      "          30170,    107, 237703, 236916,   3244]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\nĐó là một vấn đề\\nĐó là một vấn đề\\nĐó là một vấn đề\\nĐó là một vấn đề\\nĐó là']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,  26609,\n",
      "          42883,   9676,  19157,  33783,  42050,  55682, 237409, 237184,    107,\n",
      "          42883,   9676,  19157,  33783,  42050,  55682, 237409, 237184,  42883,\n",
      "           9676,  19157,  33783,  42050,  55682, 237409, 237184,  42883,   9676,\n",
      "          19157,  33783,  42050]], device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n模型训练数据处理质量保证一致性：\\n训练数据处理质量保证一致性：训练数据处理质量保证一致性：训练数据处理质量保证']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "           1018,    108,   1018,    108,   1018,    108,   1018,    108,   1018,\n",
      "            108,   1018,    108,   1018,    108,   1018,    108,   1018,    108,\n",
      "           1018,    108,   1018,    108,   1018,    108,   1018,    108,   1018,\n",
      "            108,   1018,    108,   1018]], device='cuda:0')\n",
      "output: ['<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**']\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108,  99972,  31889,  89158,   5042,  10044,\n",
      "           3884, 127379,  63719,  10044,  51414,  27888,  12835,  14780,  21587,\n",
      "         236761,    107, 237703,    581,  31889,  89158,   5042,  10044,   3884,\n",
      "         127379,  63719,  10044,  51414,  27888,  12835,  14780,  21587]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\nBạn cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\nĐem cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n",
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108,    106]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n<end_of_turn>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model_zh, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba65260-04ee-4caf-8d32-dac1061c07a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e800f-b8cb-4c06-9376-3391210efe1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82ac5334-e9bf-47de-a0d2-fb5cc415aebd",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# kur bottom1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b679ab91-3676-4e7d-8f78-e0d582047077",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_en = torch.load('/root/autodl-fs/LRP_kur_res/20251125/bottom1perc_LRP_kur_res_en.pt', weights_only=False)\n",
    "neuron_vi = torch.load('/root/autodl-fs/LRP_kur_res/20251125/bottom1perc_LRP_kur_res_vi.pt', weights_only=False)\n",
    "neuron_zh = torch.load('/root/autodl-fs/LRP_kur_res/20251125/bottom1perc_LRP_kur_res_zh.pt', weights_only=False)\n",
    "\n",
    "model_en = copy.deepcopy(model)\n",
    "model_en = set_neuron_zero(model_en, neuron_en)\n",
    "\n",
    "model_vi = copy.deepcopy(model)\n",
    "model_vi = set_neuron_zero(model_vi, neuron_vi)\n",
    "\n",
    "\n",
    "model_zh = copy.deepcopy(model)\n",
    "model_zh = set_neuron_zero(model_zh, neuron_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b908f823-407f-4427-b0b4-62b30e89233c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "********************\n",
      "model name: org_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.2627, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:32<00:00, 30.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(13.2703, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.5759, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_en_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.9548, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 30.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(13.2410, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.9520, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_vi_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:26<00:00, 37.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.3481, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:32<00:00, 30.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(12.3787, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.4910, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_zh_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.3114, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:32<00:00, 30.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(12.6794, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.3847, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "calc ppl\n",
    "\n",
    "'''\n",
    "\n",
    "# load test data\n",
    "test_en = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/en_radom_1000_test.jsonl')\n",
    "test_vi = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/vi_radom_1000_test.jsonl')\n",
    "test_zh = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/zh_radom_1000_test.jsonl')\n",
    "               \n",
    "# calc ppl\n",
    "model_list= [\n",
    "    (model, 'org_model'),\n",
    "    (model_en, 'mask_en_neuron_model'),\n",
    "    (model_vi, 'mask_vi_neuron_model'),\n",
    "    (model_zh, 'mask_zh_neuron_model'),\n",
    "]\n",
    "\n",
    "data_list = [\n",
    "    (test_en, 'en_data'),\n",
    "    (test_vi, 'vi_data'),\n",
    "    (test_zh, 'zh_data')\n",
    "    \n",
    "]\n",
    "\n",
    "for i_model, model_name in model_list:\n",
    "    print('*'*20)\n",
    "    print('*'*20)\n",
    "    print('model name:', model_name)\n",
    "\n",
    "    for i_data, data_name in data_list:\n",
    "        print('='*20)\n",
    "        print('data name:', data_name)\n",
    "        ppl_sum, ppl_count = calc_ppl(i_model, tokenizer, i_data, max_len= 2048)\n",
    "        print('ppl:',ppl_sum/ppl_count )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166eaae9-f446-4a94-95a2-983d82959531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb44f68-9487-479e-8feb-0e65396ef5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c4a84-461c-4549-b3e2-e9da70b0f6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02a196-93d2-4379-9160-f1d8a45fb7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c242e45-0e4c-4768-a610-fb3f1ddd4dbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108,   7243,    108,   1018,   4968,\n",
      "          17243,  53121,    108,   7711,   2028,    563,    496,  29193, 236772,\n",
      "           5140,   5192,   2028,  15453,    580,    496,  12566,  15297,    529,\n",
      "           1816,    532,   3393,    528,   5422, 236764,  14361, 236764,   7830]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n---\\n\\n**Model Description:**\\n\\nOur model is a transformer-based language model trained on a massive dataset of text and code in English, Spanish, French']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            108,   1018, 236792, 237124,  14960, 140907,  90687,  27869,    568,\n",
      "           2182, 236792, 236768,    753,    623, 122850,   3271, 124468, 236775,\n",
      "           1018,    108, 122850,   3271, 124468,   3244,   7325,  38325,  14960,\n",
      "         140907,  90687,  27869,   7189,  55415]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n**Mô hình ngôn ngữ lớn (LLM) - \"LinguaVerse\"**\\n\\nLinguaVerse là một mô hình ngôn ngữ lớn được xây']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,   1018,\n",
      "          26609,  92141, 237184,   1018,    108, 236829,    139,   1018,  86313,\n",
      "         236743,  92141,  53121,    138,   6932,   5938,  39738,  92474,  10363,\n",
      "          26609, 236900,  99193, 158343,  26595,   9824,  11471,  27099,  10363,\n",
      "         238017, 237501, 236924]], device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n**模型架构：**\\n\\n*   **Transformer 架构:**  我们使用基于 Transformer 的模型，特别是 BERT 和 RoBERTa 的变体。']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "           7243,    108,    818,   6573,  54850,    657,   1041,  13925,   5716,\n",
      "         236764,    496,   4512, 236764,  74693,  89830, 236761,   3551,  11762,\n",
      "           3952,    528, 134880,   4314,    975, 236764,    496,   2173, 108507,\n",
      "           2342,    506, 162542,  16045]], device='cuda:0')\n",
      "output: ['<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\n---\\n\\nThe wind bites at my exposed skin, a constant, icy whisper. My breath comes in ragged gasps, a white plume against the bruised purple']\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108, 236769, 237703, 236748,   7439,  44693,\n",
      "         100634, 236764,  22947,  31612,  13940,  31889,  89158,   3884, 127379,\n",
      "          63719, 236768,    108,   1390,    108,   1390,    108,   1390,    108,\n",
      "         236769, 217366,  37513,   6256,   8665,  38143,  67946,  11188]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\n(Đoạn văn ngắn, tập trung vào cảm xúc và khung cảnh)\\n\\n...\\n\\n...\\n\\n...\\n\\n(Hãy thêm các chi tiết cụ thể']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108, 237169,  31799,  17583,  12680, 237408, 151599,  53877, 107462,\n",
      "         237206, 216348, 236924,  14201, 237169,  33813,  12553, 236900,  31799,\n",
      "          85694,  65407,  72245, 237622,  43719, 236924,  13488, 236900, 183868,\n",
      "          21181,  22276,  19695, 236900,  92711]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n我无法直接提供你登山者的情绪和视角。因为我是一个AI，无法模拟人类的情感体验。但是，我可以根据你的要求，创作']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a05c1184-9519-4119-b62d-ac96fec56af5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108,   7243,    108,   1018,   4968,\n",
      "          39244,    833,  19779,  76242,   1018,    108,   7711,   2028,   6585,\n",
      "         132567,   2744,    684,   1171,  41110,    496, 132567,  43703,   6352,\n",
      "            531,   2754,   1546,   3658,    528,    506,   2744,   3418,   1061]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n---\\n\\n**Model Processing & Quality Assurance**\\n\\nOur model processes multilingual input by first employing a multilingual embedding layer to represent each word in the input across its']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            108,   1018, 237703,  10582,  37020,  13940,  38325,  14960, 140907,\n",
      "          90687,  27869,    568,   2182, 236792, 236768,    753, 131233,  35909,\n",
      "         100634,  96901,   1018,    108, 236792, 237124,  14960, 140907,  90687,\n",
      "          27869,    568,   2182, 236792, 236768]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n**Đầu tư vào mô hình ngôn ngữ lớn (LLM) - Giải thích ngắn gọn**\\n\\nMô hình ngôn ngữ lớn (LLM)']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,  26609,\n",
      "          19157, 237309,  37557, 180828,  42033,  92870, 237184,    108, 236770,\n",
      "         236761,    138,   1018, 238794,  19157, 237184,   1018,    138, 237392,\n",
      "          26878,  57489,  10937, 123700, 236951, 237237, 239275, 236951, 239275,\n",
      "         237409, 201281, 237520]], device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n模型处理多语言输入的关键在于：\\n\\n1.  **预处理：**  对输入文本进行清洗、分词、词性标注等']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "           7243,    108, 236769,    818,   8317,  19015,    607,    496,   5777,\n",
      "           5719,    529,    506, 113768, 236764,   3648,  10790,  77558,   2342,\n",
      "            496,  55704, 236764,   7613, 236772,  26987,  11519, 236761,    669,\n",
      "           6573,    563, 178291, 236764]], device='cuda:0')\n",
      "output: ['<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\n---\\n\\n(The scene opens with a wide shot of the climber, silhouetted against a breathtaking, snow-covered peak. The wind is howling,']\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108,   7243,    108, 236769, 236792, 237124,\n",
      "         110624,  31889,  89158,   5042,  10279,  70669, 121230,  11638, 232727,\n",
      "          57703, 114589,  94509, 236768,    108, 172915,  27600,  84655,  14780,\n",
      "         114589,  94509, 236761,    587,  19084,    637,  11992,    549]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\n---\\n\\n(Mô tả cảm xúc của người leo núi khi chinh phục đỉnh Everest)\\n\\nTôi đang đứng trên đỉnh Everest. Mưa rào g']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108, 237169,  79948, 239972, 241888, 240344, 241454, 239963, 239761,\n",
      "         237152, 236900, 238321, 239156, 244176, 237576, 236900, 237945,  32700,\n",
      "         238279, 238384,  26122, 236900, 240649, 244761, 237576,  21480, 109231,\n",
      "         236924, 237169,  67940,  36027,  85629]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n我站在珠穆朗玛峰顶上，风呼啸着，像是在低语一样，吹拂着我的头发。我感到一种难以']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model_en, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ae5d512-058b-45f5-957b-cc4ba0619efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108,   1018,  44008,  53121,    108,\n",
      "           7711,   2028,   6585, 132567,   2744,    684,   1171,  21558,    506,\n",
      "           5192,    529,    506,   2744, 236761,    138,  11407, 236764,    625,\n",
      "          16819,    496,   7501,    529,   5192, 236772,  15396,  29913,    531]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n**Explanation:**\\n\\nOur model processes multilingual input by first identifying the language of the input.  Then, it applies a sequence of language-specific transformations to']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            108,   1018, 236792, 237124,  14960,  53121, 204932,  14960, 142275,\n",
      "          14780,   6256,  49921,  49110,  15196,  29011, 236764,  21994,  16981,\n",
      "           6256,  38325,  14960, 140907,  90687,  27869,    568,   2182, 236792,\n",
      "         236768,  11408,  86340,  28211,  44693]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n**Mô hình:** Mô hình dựa trên các thuật toán học máy, sử dụng các mô hình ngôn ngữ lớn (LLM) để xử lý văn']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,   1018,\n",
      "          26609,  47710, 237184,   1018,    108, 236829,    139,   1018,  26609,\n",
      "          92141,  53121,  92474,    107, 236829,    139,   1018,  42883,   9676,\n",
      "          53121, 236743,  55088,  58868,   9676,    107, 236829,    139,   1018,\n",
      "          42883,  10573,  53121]], device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n**模型描述：**\\n\\n*   **模型架构:** Transformer\\n*   **训练数据:** 英文新闻数据\\n*   **训练方法:**']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "           7243,    108,   1018,    818,   5671,    529,    672,   8774,    563,\n",
      "            531,   3050,    506,  13690,   4100,    529,    496,   2872,  99382,\n",
      "            108,   1018,  14106,  53121,    138, 236776,  56677, 150235,    497,\n",
      "         236764,   7489, 205520,   5561]], device='cuda:0')\n",
      "output: ['<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\n---\\n\\n**The goal of this exercise is to understand the emotional impact of a character.**\\n\\n**Character:**  A seasoned mountaineer, named Silas Black']\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108,   1018, 236792, 237124, 110624,  14687,\n",
      "          31889,  89158,   5042,  10044,  53121,    108, 236829,    139,   1018,\n",
      "         236780,  28416,  89158,  53121, 141501,  31889,  27888,   7325,  18457,\n",
      "         183088,   3310,  10311,  41245, 155423,    518,   7473, 236764]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\n**Mô tả về cảm xúc của bạn:**\\n\\n*   **Cảm xúc:** Tôi cảm thấy một sự phấn khích vô bờ bến,']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108,   1018,  13590,  13850, 237184, 107462,  47710,   1018,    108,\n",
      "         238350,  47710, 237408, 129807, 236918,  65689, 236900,  21187, 237184,\n",
      "            108, 236829,    139,   1018, 107462, 236918, 113799,  65689, 237184,\n",
      "           1018, 236743, 148047, 236951, 240517]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n**第一部分：情绪描述**\\n\\n请描述你此刻的感受，包括：\\n\\n*   **情绪的总体感受：** 兴奋、悲']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model_vi, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe486b56-a966-4172-b731-649c17e7a68a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108,   7243,    108,   8291, 236789,\n",
      "         236751,    496,   2591,    529,   1217,    611,    740,   3890,    672,\n",
      "           2934, 236764,    840,    611,   1202,    531,   4903,    822,   1852,\n",
      "         236761,    108,   1018,  12703,  53121,    623, 236777,    740,  17866]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n---\\n\\nHere\\'s a example of how you can answer this question, but you need to write your own.\\n\\n**Example:** \"I can translate']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            108,   1018, 149911,  14435,  53121,    108, 236829,    139,   1018,\n",
      "          29621,  13003,  90687, 236743, 236770,  53121,    138, 236775, 172915,\n",
      "          23216,  26664,  24231,  12835,    566, 137545,   1781,    107, 236829,\n",
      "            139,   1018,  29621,  13003,  90687]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n**Ví dụ:**\\n\\n*   **Ngôn ngữ 1:**  \"Tôi cần phân tích từ vựng.\"\\n*   **Ngôn ngữ']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,  18518,\n",
      "         236900,  21480,  26609,  19157, 237309,  37557, 180828, 237298, 237671,\n",
      "         237026, 236900,  15010,  26878, 237298, 236900, 237169,  33268, 237279,\n",
      "          43120,  26878,  57489, 236918,  59738, 236900,  99193,  62779,  26878,\n",
      "         236900,   9522,  59738]], device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n好的，我的模型处理多语言输入的时机是，用户输入时，我首先会检查输入文本的长度，特别是第一个输入，如果长度']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "         236769, 236777, 236789,    560,   1010,  29967,    573,   5695, 236764,\n",
      "            532,    564, 236789, 236757,   6250,    531,   2597,   1390,  46002,\n",
      "           2907,    108,   1509, 236789, 236751,    496,  17163,   8178, 236764,\n",
      "           5889, 236789, 236745,    625]], device='cuda:0')\n",
      "output: [\"<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\n(I've been climbing for weeks, and I'm starting to feel... overwhelmed.)\\n\\nIt's a strange feeling, isn't it\"]\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108,   7243,    108,   1018, 236780,  28416,\n",
      "          89158,  53121,    108, 172915,  27600,  84655,  14780, 114589,  94509,\n",
      "         236764,   7325,  18457,    757, 204821,  38042,   3375,  37814,  29834,\n",
      "            719, 145515, 236761,  85654,   4032,  42122,  14759,   1123]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\n---\\n\\n**Cảm xúc:**\\n\\nTôi đang đứng trên đỉnh Everest, một sự im lặng kinh ngạc bao trùm. Không có tiếng lá x']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108,  21480, 107462, 236900, 237026, 239783, 206306, 236900, 237945,\n",
      "         155059, 237759, 240379, 246637, 236918, 191885, 236924, 237169,  66249,\n",
      "         237075, 237845, 237652, 236900, 237075, 237383, 238330, 238097, 236900,\n",
      "         237169,  66249,  67940, 182705, 236900]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n我的情绪，是冰冷的，像一块被磨砺的石头。我曾经在山里，在最深处，我曾经感到孤独，']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model_zh, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62257714-82ae-422f-b312-e950b98bd1a0",
   "metadata": {},
   "source": [
    "## kur gap rate top 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d398142-2296-47c7-9ff5-37cfd7c5671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_en = torch.load('/root/autodl-fs/LRP_kur_res/20251125/gaprate_top1perc_LRP_kur_res_en.pt', weights_only=False)\n",
    "neuron_vi = torch.load('/root/autodl-fs/LRP_kur_res/20251125/gaprate_top1perc_LRP_kur_res_vi.pt', weights_only=False)\n",
    "neuron_zh = torch.load('/root/autodl-fs/LRP_kur_res/20251125/gaprate_top1perc_LRP_kur_res_zh.pt', weights_only=False)\n",
    "\n",
    "model_en = copy.deepcopy(model)\n",
    "model_en = set_neuron_zero(model_en, neuron_en)\n",
    "\n",
    "model_vi = copy.deepcopy(model)\n",
    "model_vi = set_neuron_zero(model_vi, neuron_vi)\n",
    "\n",
    "\n",
    "model_zh = copy.deepcopy(model)\n",
    "model_zh = set_neuron_zero(model_zh, neuron_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93f4dc00-5487-4cc6-a394-1860dc1b356f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n"
     ]
    }
   ],
   "source": [
    "min_num = -100\n",
    "for name, param in model.named_parameters():\n",
    "        # 检查参数是否有梯度\n",
    "        #print(name,  param.shape)\n",
    "        cur_min = param.max().item()\n",
    "\n",
    "        min_num= max(min_num, cur_min)\n",
    "print(min_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e16bc5db-b4a2-4867-a264-c368a68138e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "********************\n",
      "model name: org_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.2627, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 30.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(13.2703, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.5759, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_en_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.7718, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 30.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.1426, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(9.6979, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_vi_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.4110, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 30.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.4656, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(9.7227, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_zh_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:26<00:00, 37.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.1620, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 30.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.0114, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(9.4460, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "calc ppl\n",
    "\n",
    "'''\n",
    "\n",
    "# load test data\n",
    "test_en = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/en_radom_1000_test.jsonl')\n",
    "test_vi = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/vi_radom_1000_test.jsonl')\n",
    "test_zh = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/zh_radom_1000_test.jsonl')\n",
    "               \n",
    "# calc ppl\n",
    "model_list= [\n",
    "    (model, 'org_model'),\n",
    "    (model_en, 'mask_en_neuron_model'),\n",
    "    (model_vi, 'mask_vi_neuron_model'),\n",
    "    (model_zh, 'mask_zh_neuron_model'),\n",
    "]\n",
    "\n",
    "data_list = [\n",
    "    (test_en, 'en_data'),\n",
    "    (test_vi, 'vi_data'),\n",
    "    (test_zh, 'zh_data')\n",
    "    \n",
    "]\n",
    "\n",
    "for i_model, model_name in model_list:\n",
    "    print('*'*20)\n",
    "    print('*'*20)\n",
    "    print('model name:', model_name)\n",
    "\n",
    "    for i_data, data_name in data_list:\n",
    "        print('='*20)\n",
    "        print('data name:', data_name)\n",
    "        ppl_sum, ppl_count = calc_ppl(i_model, tokenizer, i_data, max_len= 2048)\n",
    "        print('ppl:',ppl_sum/ppl_count )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d970d8-9694-4898-b7aa-4d6e3bb9525a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088056de-6846-415d-ae9a-8bf058328319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd506ff3-396f-4767-872e-059c77057f37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108,  19058, 236764,   1590, 236789,\n",
      "         236751,    496,  12262,   3072,    600,    611,    740,   1161,    618,\n",
      "            496,   6250,   1523, 236761,    138,   1509, 236789, 236751,   5402,\n",
      "            531,    577,   3582, 236764,  63510, 236764,    532,   3421,    506]],\n",
      "       device='cuda:0')\n",
      "output: [\"<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\nOkay, here's a draft response that you can use as a starting point.  It's designed to be clear, concise, and address the\"]\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            108,   1018, 237703, 237449,  57694,  13428,   6256,  15289,  67946,\n",
      "           3884,  69406,  49921,   1018,    108,   1018, 237703,  19084,   1459,\n",
      "           7325,  13960,  14435,   1018,    108,   1018,  71251,  61386,  44731,\n",
      "          53121,    108,   1018, 236770, 236761]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n**Đề cập đến các công cụ và kỹ thuật**\\n\\n**Đưa ra một ví dụ**\\n\\n**Câu trả lời:**\\n\\n**1.']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,   1018,\n",
      "          26609,  47710,  53121,    108,  21480,  26609,  33813,  39738,  86313,\n",
      "         236918,  37557,  26609, 236900,   5157,  19157,  79403,  37557, 236924,\n",
      "         238010,  12982,  19697,  16772,  19157, 237309,  37557,  26878, 237184,\n",
      "            108, 236770, 236761]], device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n**模型描述:**\\n\\n我的模型是一个基于Transformer的语言模型，可以处理多种语言。它通过以下方式处理多语言输入：\\n\\n1.']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "           7243,    108,    818,   6573,   1217,    991,    496,  92377,   1275,\n",
      "           5410,   2101,    786, 236764,    496,   4512, 236764,  74693,  89830,\n",
      "            600,  13804,    529,    506,  36628,   2066,    529,    672,  10565,\n",
      "         236761,   3551,  38464,  30494]], device='cuda:0')\n",
      "output: ['<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\n---\\n\\nThe wind howled a mournful song around me, a constant, icy whisper that spoke of the immense power of this mountain. My lungs burned']\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108,   7243,    108, 172915,  12105, 232727,\n",
      "          57703, 114589,  94509, 236761,    108, 236780,  28416,  89158,   5042,\n",
      "          25969,  42645,  16420,   3244,   7325,  18457,   3375,  37814,  30166,\n",
      "         236761,  85654,  11188,  13657,  35051,  13892,  12105, 120535]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\n---\\n\\nTôi đã chinh phục đỉnh Everest.\\n\\nCảm xúc của tôi lúc đầu là một sự ngạc nhiên. Không thể tin rằng mình đã vượt']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108,  22276, 107462, 237184,    108, 236829,    139,   1018, 148047,\n",
      "          53121, 236743, 242958, 238603, 239972, 241888, 240344, 241454, 239963,\n",
      "         236918,  63417, 236900, 237026,  78747,  67940, 143174, 236918, 148047,\n",
      "         236900, 111000, 237169,  34775,  63417]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n你的情绪：\\n\\n*   **兴奋:** 攀登珠穆朗玛峰的经历，是让我感到无比的兴奋，仿佛我正在经历']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model_en, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "962356b5-8399-40b3-9d05-dbad29c4c9db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108,   1018,   7925,  53121,    108,\n",
      "           7711,   2028,   6585, 132567,   2744,    684,   1171,  35322,    625,\n",
      "            531,    496,   7659,  10065,   2557,   1699,    496, 132567,  43703,\n",
      "           6352, 236761,   1174,   6352,  53228,    531,   4187,   4171,   3418]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n**Answer:**\\n\\nOur model processes multilingual input by first converting it to a shared representation space using a multilingual embedding layer. This layer learns to map words across']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            108,   1018,  71251,  47421,  53121,    107,  68850,  35187,  20421,\n",
      "          28668,  41926,   5042,  38325,  14960, 236764,  10044,  12105,  58805,\n",
      "          18470,  11388, 207204,  23103,  23336,   3884,  10044,  12105,  28206,\n",
      "          54292,  16427,  10539,  21121,  22336]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n**Câu hỏi:**\\nTrong quá trình phát triển của mô hình, bạn đã gặp phải những thách thức gì và bạn đã giải quyết chúng như thế nào']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,   1018,\n",
      "          26609,  19157, 237309,  37557,  26878, 237184,   1018,    108,  21480,\n",
      "          26609,  22194,  19157,  79403,  37557, 236918,  26878, 236900,  21187,\n",
      "          55041, 236951,  55088, 236951, 138608, 238384, 236951, 238624, 238384,\n",
      "         236951, 118699, 236951]], device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n**模型处理多语言输入：**\\n\\n我的模型能够处理多种语言的输入，包括中文、英文、西班牙语、德语、法语、']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "            818,   6573,    563,    496,  40097, 236764,  85278,   4912, 236764,\n",
      "         148443,   1041,   3392,    532, 188312,   1041,   6114, 236761,    669,\n",
      "           7613,    563,    496, 186350,   2173, 236764,    496,   4512, 236764,\n",
      "          34064,  10092, 236761,    564]], device='cuda:0')\n",
      "output: ['<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\nThe wind is a brutal, relentless force, whipping my face and stinging my eyes. The snow is a blinding white, a constant, shifting landscape. I']\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108,   7243,    108,  99972,   3244,   7325,\n",
      "          10279,  70669, 121230,  50971, 232727,  57703, 114589,  94509, 236761,\n",
      "          88170,  38325, 110624,  31889,  89158,   5042,  10044,   3884, 127379,\n",
      "          63719,  10044,  51414,  27888,  12835,  14780,  21587, 236761]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\n---\\n\\nBạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108, 237169,  16884, 237606, 151599, 237457, 236900, 237169, 223874,\n",
      "         239972, 241888, 240344, 241454, 239963, 239761, 239963, 236924,    108,\n",
      "         237169,  79948, 237845, 239761, 236900, 237169,  67940,  36027,  85629,\n",
      "         237748, 237906, 236918, 236951,  62637]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n我是一位登山者，我登上珠穆朗玛峰顶峰。\\n\\n我站在山顶，我感到一种难以置言的、令人']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model_vi, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd7ff12b-4b27-4602-88dc-c3c0f978c543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108,   8291, 236789, 236751,    496,\n",
      "           5498,   3072, 236787,    108,   1018,   4968,  39244,  53121,    108,\n",
      "           4754,   2028,   6585, 132567,   2744,    684,   1171,  21558,    506,\n",
      "           5192,    529,   1546,   8369,   1699,    496,   5192,   2028, 236761]],\n",
      "       device='cuda:0')\n",
      "output: [\"<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\nHere's a sample response:\\n\\n**Model Processing:**\\n\\nMy model processes multilingual input by first identifying the language of each token using a language model.\"]\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            108,   7243,    107,    107,  99972,    636,    538,    496,    538,\n",
      "            512,    566,    496,    538,    534,    512,    510,    534,    512,\n",
      "            538,    494,    534,    512,    510,    534,    496,    538,    494,\n",
      "            534,    496,    538,    494,    534]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n---\\n\\nBạn se n a n o v a n h o p h o n t h o p h a n t h a n t h']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,  10180,\n",
      "          26609, 237026,  39738,  70126,  23486, 236900,   5938,   5095,  56762,\n",
      "          37557,  26609, 236900, 237853,   5938,   5095, 239275, 240433,  44525,\n",
      "         236924,    108, 238350,  12680,  18303,  31580,  19809,  54003,  26609,\n",
      "         236900, 237162,  32690]], device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n这个模型是基于深度学习，使用一个大型语言模型，并使用一个词汇数据库。\\n\\n请提供一些关于如何优化模型，以提高']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "            818,   1657,    529,  17154,    506,  34976,    563,    496,  16438,\n",
      "         236764,    496,  85278,  17085,   2342,    506,  76789,   7445, 236764,\n",
      "            506,  11202,   2634, 236764,    532,    506,  37501,   3825,    529,\n",
      "            506,   3294, 236761,   2024]], device='cuda:0')\n",
      "output: ['<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\nThe process of reaching the summit is a struggle, a relentless climb against the biting cold, the thin air, and the sheer weight of the pack. But']\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108,   7243,    107,    107,   1018, 236780,\n",
      "          28416,  89158,   5042,   7325,  10279,  70669, 121230,   1018,    108,\n",
      "         236792,  19084,  10539,    719,  19834, 236764, 151243,  92108,  10539,\n",
      "          56246, 236761,    107, 172915,  27600,  84655,  14780, 114589]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\n---\\n\\n**Cảm xúc của một người leo núi**\\n\\nMưa như trăng, gió lạnh như dao.\\nTôi đang đứng trên đỉnh']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108, 237169,  10042, 237169, 237282, 237169, 237648, 236900,    107,\n",
      "         237169,  10042,   5095,    107, 236829,    107,    138,    107,    138,\n",
      "            107,    138,    107,    138,    107,    138,    107,    138,    107,\n",
      "            138,    107,    138,    107,    138]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n我需要我来我去，\\n我需要一个\\n*\\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model_zh, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d73882-29be-4daf-9f8d-4d215e3637dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d6599-0c21-4837-b77a-6fe737ef4244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab042bed-1a69-4ad7-b996-967ae995d8ec",
   "metadata": {},
   "source": [
    "## kur gap rate bottom 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20ce1461-9254-4747-926d-e7d61049c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_en = torch.load('/root/autodl-fs/LRP_kur_res/20251125/gaprate_bottom1perc_LRP_kur_res_en.pt', weights_only=False)\n",
    "neuron_vi = torch.load('/root/autodl-fs/LRP_kur_res/20251125/gaprate_bottom1perc_LRP_kur_res_vi.pt', weights_only=False)\n",
    "neuron_zh = torch.load('/root/autodl-fs/LRP_kur_res/20251125/gaprate_bottom1perc_LRP_kur_res_zh.pt', weights_only=False)\n",
    "\n",
    "model_en = copy.deepcopy(model)\n",
    "model_en = set_neuron_zero(model_en, neuron_en)\n",
    "\n",
    "model_vi = copy.deepcopy(model)\n",
    "model_vi = set_neuron_zero(model_vi, neuron_vi)\n",
    "\n",
    "\n",
    "model_zh = copy.deepcopy(model)\n",
    "model_zh = set_neuron_zero(model_zh, neuron_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a816985-04d6-4835-9f81-fd0f80ccdd3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "********************\n",
      "model name: org_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.2627, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 30.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(13.2703, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.5759, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_en_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(18.4616, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 30.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(17.1368, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(21.3397, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_vi_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(24.0838, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 30.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(24.9086, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(23.7898, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_zh_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:26<00:00, 37.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(21.9303, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:32<00:00, 30.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(25.0321, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(24.3280, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "calc ppl\n",
    "\n",
    "'''\n",
    "\n",
    "# load test data\n",
    "test_en = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/en_radom_1000_test.jsonl')\n",
    "test_vi = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/vi_radom_1000_test.jsonl')\n",
    "test_zh = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/zh_radom_1000_test.jsonl')\n",
    "               \n",
    "# calc ppl\n",
    "model_list= [\n",
    "    (model, 'org_model'),\n",
    "    (model_en, 'mask_en_neuron_model'),\n",
    "    (model_vi, 'mask_vi_neuron_model'),\n",
    "    (model_zh, 'mask_zh_neuron_model'),\n",
    "]\n",
    "\n",
    "data_list = [\n",
    "    (test_en, 'en_data'),\n",
    "    (test_vi, 'vi_data'),\n",
    "    (test_zh, 'zh_data')\n",
    "    \n",
    "]\n",
    "\n",
    "for i_model, model_name in model_list:\n",
    "    print('*'*20)\n",
    "    print('*'*20)\n",
    "    print('model name:', model_name)\n",
    "\n",
    "    for i_data, data_name in data_list:\n",
    "        print('='*20)\n",
    "        print('data name:', data_name)\n",
    "        ppl_sum, ppl_count = calc_ppl(i_model, tokenizer, i_data, max_len= 2048)\n",
    "        print('ppl:',ppl_sum/ppl_count )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7994f868-8a43-4344-8076-ae5cf61e412d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:02<00:13,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108,   7243,    108,   1018,   4968,\n",
      "          17243,  53121,    108,   7711,   2028,    563,    496,  29193, 236772,\n",
      "           5140,   5192,   2028,  15453,    580,    496,  12566,  15297,    529,\n",
      "           1816,    532,   3393,    528,   5422, 236764,  14361, 236764,   7830,\n",
      "         236764,    532,   9115, 236761,   1030,  60432,    496,   5074, 236772,\n",
      "         187918,  43703,   6352,    531,   2754,   1546,   5192,    618,    496,\n",
      "           3550,    528,    496,   7659,   2557, 236761,    138,  14521,  34711,\n",
      "         236764,    506,   2028,  52298,    506,   2148,   8369,    528,    506,\n",
      "           7501, 236764,  11337,    506,   4403,    529,    506,   4251,   2744,\n",
      "         236764,   2440,    506,   3738,   5192, 236761,    138,   1882,   2736,\n",
      "            496,  26446,   5700,  10241,    600,   5862,    506,   2028,    531,\n",
      "          19281,    506,   8020,    529,   1607,  15579,   1056,   8487,    496,\n",
      "           2238,   2744, 236761,    138,  41781, 236764,    692,  27968,    496,\n",
      "           5192, 236772,  15396,  53255,   7545, 236764,  39919,    506,   3938,\n",
      "           6518,   2721,    580,    506,  13207,   5192]], device='cuda:0')\n",
      "output: ['<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n---\\n\\n**Model Description:**\\n\\nOur model is a transformer-based language model trained on a massive dataset of text and code in English, Spanish, French, and German. It utilizes a multi-lingual embedding layer to represent each language as a vector in a shared space.  During inference, the model predicts the next token in the sequence, considering the context of the entire input, including the source language.  We employ a sophisticated attention mechanism that allows the model to weigh the importance of different languages when processing a given input.  Furthermore, we incorporate a language-specific decoding strategy, adjusting the output format based on the detected language']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:05<00:11,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            108,   1018, 236792, 237124,  14960, 140907,  90687,  27869,    568,\n",
      "           2182, 236792, 236768,    753,    623, 122850,   3271, 124468, 236775,\n",
      "           1018,    108, 122850,   3271, 124468,   3244,   7325,  38325,  14960,\n",
      "         140907,  90687,  27869,   7189,  55415,  54380, 142275,  14780,  50793,\n",
      "         124290,  92474, 236761,  91509,   7189, 200755, 100370,  14780,   7325,\n",
      "          21682,  27869,  79808,  35112,  44693,  28035,  48078, 140907,  90687,\n",
      "         236764,  29834,  43790,  42292, 236764,  48415, 236764,  29956,   4108,\n",
      "         236764,  31089,  62805,   3884,   6256,  62805,  22582, 236761,    138,\n",
      "         122850,   3271, 124468,  21994,  16981,   7325,  28749,  37944,    623,\n",
      "            791,   5419,  22027, 140907,  90687, 236775,    568,  19859, 236772,\n",
      "          22426,  34684, 236768,  11408,  86340,  28211,  79808,  35112,  48078,\n",
      "         140907,  90687, 236761,    108,   1018, 135709,  86340,  28211,  79808,\n",
      "          35112,  48078, 140907,  90687,  53121,    108, 236770, 236761,   5213,\n",
      "           3586,   5419,  22027, 140907,  90687,  53121,    138, 199259,  11638,\n",
      "         200755, 100370]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n**Mô hình ngôn ngữ lớn (LLM) - \"LinguaVerse\"**\\n\\nLinguaVerse là một mô hình ngôn ngữ lớn được xây dựng dựa trên kiến trúc Transformer. Nó được huấn luyện trên một lượng lớn dữ liệu văn bản đa ngôn ngữ, bao gồm sách, báo, trang web, mã nguồn và các nguồn khác.  LinguaVerse sử dụng một hệ thống \"phân chia ngôn ngữ\" (language-aware splitting) để xử lý dữ liệu đa ngôn ngữ.\\n\\n**Cách xử lý dữ liệu đa ngôn ngữ:**\\n\\n1. **Phân chia ngôn ngữ:**  Trước khi huấn luyện']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:08<00:08,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,   1018,\n",
      "          26609,  92141, 237184,   1018,    108, 236829,    139,   1018,  86313,\n",
      "         236743,  92141,  53121,    138,   6932,   5938,  39738,  92474,  10363,\n",
      "          26609, 236900,  99193, 158343,  26595,   9824,  11471,  27099,  10363,\n",
      "         238017, 237501, 236924,    107, 236829,    139,   1018, 238794,  42883,\n",
      "          53121, 228546, 237075,  41440, 122462, 238384, 237616, 238956, 237221,\n",
      "          34313, 236900,  19892,  42761, 236752, 236764,  24612, 236764,  20980,\n",
      "           9521,  21553, 237214, 237152, 238794,  42883, 236924,    107, 236829,\n",
      "            139,   1018, 238477, 238250,  53121,    138, 237075,  60009,  34769,\n",
      "         237221,  34313, 236900,  51231,  90194, 236951, 237889, 238843, 237214,\n",
      "         237152,  10937, 238477, 238250, 236924,    108,   1018, 237309,  37557,\n",
      "          19157,  59322, 237184,   1018,    108, 236770, 236761,    138,   1018,\n",
      "          37557,  45010,  53121,    138, 237075,  26878,  57489, 237103,  10937,\n",
      "          37557,  45010, 236900,  77100, 237191,  26878,  57489, 236918,  37557,\n",
      "         236924,    107, 236778, 236761,    138,   1018,  37557, 160266,  53121]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n**模型架构：**\\n\\n*   **Transformer 架构:**  我们使用基于 Transformer 的模型，特别是 BERT 和 RoBERTa 的变体。\\n*   **预训练:** 模型在大量平行语料库（例如，Common Crawl, Wikipedia, BooksCorpus）上预训练。\\n*   **微调:**  在特定任务（例如，机器翻译、问答）上进行微调。\\n\\n**多语言处理策略：**\\n\\n1.  **语言检测:**  在输入文本中进行语言检测，识别出输入文本的语言。\\n2.  **语言适配:**']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:11<00:05,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "           7243,    108,    818,   6573,  54850,    657,   1041,  13925,   5716,\n",
      "         236764,    496,   4512, 236764,  74693,  89830, 236761,   3551,  11762,\n",
      "           3952,    528, 134880,   4314,    975, 236764,    496,   2173, 108507,\n",
      "           2342,    506, 162542,  16045,    529,    506,   7217, 236761,   1701,\n",
      "           5695, 236764,    564, 236858,    560,   1010,  60821,    506,   4820,\n",
      "         236764,  22224,   1041,   2742,    531,   1061,  10298,   4576, 236764,\n",
      "            532,   1492, 237064,   1492,    625, 236858, 236751,    784,   5367,\n",
      "            625, 236761,    564, 236858,    560,   8452,    506,  34976,    529,\n",
      "           9348,  94509, 236761,    108, 236776,   6794,    529,   8176, 236764,\n",
      "            723,    553, 109064,    774,  12690,  93084,   1024,    786, 236764,\n",
      "            834,  18487,    625,  75583,    531,  77937,   1041,  40027, 236761,\n",
      "           1030, 236858, 236751,    711,   1164,  11277, 236764,    625, 236858,\n",
      "         236751,    496,   8178,    529,  27725, 236764,   4180,  15596,   5603,\n",
      "         236761,    564, 236858,    560,   7785,   1041,   1972,  67301,    529,\n",
      "            672]], device='cuda:0')\n",
      "output: ['<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\n---\\n\\nThe wind bites at my exposed skin, a constant, icy whisper. My breath comes in ragged gasps, a white plume against the bruised purple of the sky. For weeks, I’ve been battling the elements, pushing my body to its absolute limit, and now… now it’s all worth it. I’ve reached the summit of Mount Everest.\\n\\nA wave of pure, unadulterated joy washes over me, so intense it threatens to buckle my knees. It’s not just relief, it’s a feeling of profound, almost spiritual connection. I’ve spent my life dreaming of this']\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:13<00:02,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108, 236769, 237703, 236748,   7439,  44693,\n",
      "         100634, 236764,  22947,  31612,  13940,  31889,  89158,   3884, 127379,\n",
      "          63719, 236768,    108,   1390,    108,   1390,    108,   1390,    108,\n",
      "         236769, 217366,  37513,   6256,   8665,  38143,  67946,  11188,  14687,\n",
      "          31889,  89158,   3884, 127379,  63719, 236768,    108,   1018, 149911,\n",
      "          14435,  53121,    108, 236775, 236780,  28416,  89158,   5042,  25969,\n",
      "           3244,   7325,  18457,  26220,  18234,  39652,  18457,   3375,  37814,\n",
      "          30166, 236764,    566, 239731, 236743,  46524,   3884,   7325,  87062,\n",
      "         132076,    534,  66928, 236761,    587,  19084,    637,  11992,  29834,\n",
      "          86569,  29818,  28059, 114589,  94509, 236764,  27876,  25969,  41533,\n",
      "          51414,  27888,  11388,    566, 103294,  98220,    537,  18496,  14759,\n",
      "           2313,  14780,  11388,    494,  19712,  59407, 236761,  90893,  14780,\n",
      "          21587, 236764,  25969,  31889,  27888,  10539,  13892,  27600,   7189,\n",
      "          29834,  84782,  48083,   7325,  21121,  32025,  48580,  27869, 236764,\n",
      "          56250,  32634,  48247, 236764,   3884]], device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\n(Đoạn văn ngắn, tập trung vào cảm xúc và khung cảnh)\\n\\n...\\n\\n...\\n\\n...\\n\\n(Hãy thêm các chi tiết cụ thể về cảm xúc và khung cảnh)\\n\\n**Ví dụ:**\\n\\n\"Cảm xúc của tôi là một sự kết hợp giữa sự ngạc nhiên, vỡ òa và một chút sợ hãi. Mưa rào bao phủ toàn bộ đỉnh Everest, nhưng tôi vẫn nhìn thấy những vầng dương lấp lánh trên những tảng đá. Từ trên cao, tôi cảm thấy như mình đang được bao quanh bởi một thế giới rộng lớn, đầy màu sắc, và']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:16<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108, 237169,  31799,  17583,  12680, 237408, 151599,  53877, 107462,\n",
      "         237206, 216348, 236924,  14201, 237169,  33813,  12553, 236900,  31799,\n",
      "          85694,  65407,  72245, 237622,  43719, 236924,  13488, 236900, 183868,\n",
      "          21181,  22276,  19695, 236900,  92711,  71553,  31818, 236900,  85694,\n",
      "         237408, 223874, 239972, 241888, 240344, 241454, 239963, 239761, 239963,\n",
      "         236918,  65689, 236900, 237853,  47710, 237408, 237403, 187945, 143572,\n",
      "         236924,    108, 238350,  18577, 236900,  19697,  31818, 238938, 237242,\n",
      "         239852, 238450, 236900, 167467,  45370,  22276,  19695, 236924,    108,\n",
      "           1018,  21480, 107462, 237184,   1018,    108, 237169,  67940,  36027,\n",
      "          85629, 237906, 242588, 236918, 240470, 242894, 236924, 237227, 149885,\n",
      "         237026, 183622, 236900, 237611,  59013, 156076, 236918, 236951,  62637,\n",
      "         244071, 238008, 236918, 201441, 236924, 237169,  67940,   7604, 237658,\n",
      "          71216, 236918, 245540, 237369, 236900, 237658,  70828, 236918, 240874,\n",
      "         241089, 236924, 237169,  67940,  36027,  85629, 237518, 238172, 236918,\n",
      "         187036, 236900]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n我无法直接提供你登山者的情绪和视角。因为我是一个AI，无法模拟人类的情感体验。但是，我可以根据你的要求，创作一段文字，模拟你登上珠穆朗玛峰顶峰的感受，并描述你所看到的景色。\\n\\n请注意，以下文字仅为虚构，旨在满足你的要求。\\n\\n**我的情绪：**\\n\\n我感到一种难以言喻的敬畏。这不仅仅是恐惧，更是一种深深的、令人窒息的震撼。我感到自己与地球的渺小，与宇宙的宏伟。我感到一种难以名状的平静，']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd40de56-e20a-4b9a-903b-771f33ab88e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:03<00:16,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,  25681,    600,   1581,   1581,   1581,\n",
      "           1581,   1581,  15152,    919,    919,    919,    919,    919,    919,\n",
      "            659,    659,    659,    659,    659,    659,    659,    886,   5467,\n",
      "          25681,   1581,   8427,   6269,    783,    564,    564,    564,    107,\n",
      "            586,   5467,  13058,    886,   5467,    699,    107,    107,    107,\n",
      "            107,    107,    107,    107,    107,    107,    107,    107,    107,\n",
      "            107,    107,    645,    107,    645,    107,    645,    107,    645,\n",
      "            107,    645,    107,    107,    645,    107,    107,    645,    107,\n",
      "            645,    107,    645,    107,    645,    107,    645,    107,    645,\n",
      "            107,    645,    107,   8772,    107,  94728,    107,    799,    107,\n",
      "         111856,    107,    997,    107,   2048,    107,   2048,    107,  87720,\n",
      "            107, 192300, 242238,    107,    107,    107, 192300, 242238,    107,\n",
      "            107,    107,    107,    107,    107,    107,    107,    107,  57004,\n",
      "          14679,    107,    107,   1454,   3122,  14679,    107,  14679,    107,\n",
      "          14679,    107,  14679,    107,  14679,    107]], device='cuda:0')\n",
      "output: ['<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages. barely that even even even even even newly more more more more more more are are are are are are are one directly barely even slightly completely . I I I\\nly directly carefully one directly from\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n E\\n E\\n E\\n E\\n E\\n\\n E\\n\\n E\\n E\\n E\\n E\\n E\\n E\\n E\\n Bu\\n Idi\\n In\\n Inoltre\\n #\\n prote\\n prote\\n ________\\n provved̂\\n\\n\\n provved̂\\n\\n\\n\\n\\n\\n\\n\\n\\n Ai ’\\n\\n </ В ’\\n ’\\n ’\\n ’\\n ’\\n']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:06<00:11,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            107,    532,    107,    107,    107,    107,    107,    107,    107,\n",
      "            107,    107,    107,    107,    107,    107,    107,    107,    107,\n",
      "            107,    107,    107,    107,    107,    107,    107,    107,    107,\n",
      "            107,    107,    107,    107,    107,    107,    107,    107,    107,\n",
      "            107,    603, 237006, 237006,   8772,   8772,  61112,  50811, 242238,\n",
      "           2907,  14679,  14679,  14679,  14679,    107,  14679,    107,  14679,\n",
      "            107,   1732,    107,   1732,    107, 236799,   1732,    107,   1732,\n",
      "            107,  70855,  14679,    107,   1732,   1732, 236768, 184551,  29273,\n",
      "            107, 233689,   1732, 233689,   8119,  14679,    107, 242238,    107,\n",
      "         233689, 176109, 111856,  14679, 137079,   3122, 111856,  17273,  14679,\n",
      "            107, 111856, 242238,    107,   2907, 242238,    107,  82259, 111856,\n",
      "          80267, 170906, 160125, 160125,    394,    394,  74101,   8336,    394,\n",
      "          50950,   2907,    107, 238960,    107,   2907,    107,    394,    107,\n",
      "         111856, 169060, 236743,   3122, 111856, 169060, 169060, 169060, 169060,\n",
      "         169060, 169060]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n and\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Bणण Bu Bu volteDirê.) ’ ’ ’ ’\\n ’\\n ’\\n )\\n )\\nB )\\n )\\nżyt ’\\n ) )).”) į\\n Į ) Į З ’\\n̂\\n Į Perché Inoltre ’ Zim В Inoltre می\\u200c ’\\n Inoltrê\\n.)̂\\n entram Inoltre)” fornire TabLayout TabLayout�� potrebbe tent� debit.)\\nЮ\\n.)\\n�\\n Inoltre असू  В Inoltre असू असू असू असू असू असू']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:08<00:08,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,   4875,   4875,\n",
      "            107,  41077,  46366,    545,  78675, 237194,  23113, 237629,  32703,\n",
      "            107,   2613,    107,    107,   1664,   7394,  49992, 238272,    532,\n",
      "            699,    517,    532,  27461,    107,   6124,  65635,    107,   1734,\n",
      "            107, 236772,   1345,  65635, 116474,    107, 236761,   7856,    107,\n",
      "            107,    107,    107,    107,    107,    107,    107,    107,    107,\n",
      "            107,    107,    107,    107,    107,    107,    107,    107,    107,\n",
      "            107,    107,    107,    107,    107,    107,    107,    107,    107,\n",
      "            107,    107,    107,    107,    107,  24982,  48461,  25681,  14679,\n",
      "          14679,  14679,    107, 236789,    107, 236789,  48461,   1732,    107,\n",
      "         240104, 232408,  80267,  34094,    107,    199,    107,  45200, 111856,\n",
      "         101365,  14679,   1732,   1732,   1732, 137723,  13759,   1732,    107,\n",
      "          31413, 104338, 104338, 102932, 101365, 244290,   6404,  55664,    564,\n",
      "         110212, 110212,   3526,   1197,  74101, 138694,    107,  24919,    107,\n",
      "          24919,  99722,  17322, 241783, 138694,   5686, 138694,   1975, 160859]],\n",
      "       device='cuda:0')\n",
      "output: [\"<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。 trying trying\\n stesso andre e ולમような個 उदा\\n something\\n\\n tra otherwise अग्र題 and from f and erst\\nedsじめ\\npre\\n- endじめ eviden\\n. sto\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n sia Β barely ’ ’ ’\\n'\\n' Β )\\nΒ cervello)” significa\\n<em>\\n زیر Inoltre परत ’ ) ) ) Versuch bare )\\n poi direttamente direttamente preven परतẬपीrizz I aiut aiut ist bu potrebbe intento\\n oso\\n oso dessous bere冊 intento attempt intento stand diventare\"]\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:11<00:05,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    107,\n",
      "          15152,   2847,   1975,   1975,   1975,   1975,   1975,   1975,  10701,\n",
      "            107,    919,   2847,    886,    538,   2344,    919,    107,    107,\n",
      "         236764, 236764, 236764,    107, 236761, 236761, 236761, 236761, 236761,\n",
      "         236761, 236761, 236761, 236761,   1975,   1975,  31440, 237698,    538,\n",
      "            107,    107,    107,    602,    107,    538,   5467,   1003,    538,\n",
      "            538,    107, 236797,    107, 236777,    564,    577,   1197,   2979,\n",
      "            886,    107,    107,    107,    107,    107,    107,    107,    107,\n",
      "            107,    107,    107,    107,    107,    107,    107,    107,    107,\n",
      "            107,    107,    107,    107,    107,    107,  73105,   3122,    756,\n",
      "            107,   7031,    108,    107, 196923,    756, 236743,  14679,    107,\n",
      "            538,    107,    107,  34094,    107,  14679,    107,    756,  14679,\n",
      "            107,  14679,    107,  14679,    107,    593,    107,  14679,    107,\n",
      "          14679,    107,  14679,    107,  14679,    107,  14679,    107,  14679,\n",
      "            107,  14679,    107,  14679,    107,  14679,    107,  14679,    107,\n",
      "          14679]], device='cuda:0')\n",
      "output: [\"<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n newly provide stand stand stand stand stand stand mine\\n more provide one n less more\\n\\n,,,\\n......... stand standprendț n\\n\\n\\nun\\n n directly about n n\\nN\\nI I be bu values one\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n)% В '\\nรับ\\n\\n\\n خب '  ’\\n n\\n\\n significa\\n ’\\n ' ’\\n ’\\n ’\\n P\\n ’\\n ’\\n ’\\n ’\\n ’\\n ’\\n ’\\n ’\\n ’\\n ’\\n ’\"]\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:14<00:02,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    107,  17235, 237211,  10663,    107, 236764,\n",
      "         236764,  58390,  58390,  58390,    107,    107,    107,    107,    107,\n",
      "            107,    107,    107,    107, 236743,    107,    107,    107,    107,\n",
      "            107,   1100,    107,    107,    107,    107,    107,    107,    107,\n",
      "            107,    107,    107,    107,    107,    107,    107,    603,    107,\n",
      "         158348,    107, 158348,  83718,  14679,  14679,  14679,    107,  60668,\n",
      "          14679,    107,  23517,    107,  81442,    107,  14679,    107,  14679,\n",
      "            107,    562,    107,  14679,    107,  14679,    107,  14679,    107,\n",
      "          14679,    107,   1732,   1732,    107,  23676,  14679,  14679,    107,\n",
      "          17679,  14679,   1732,    107, 111856,  14679,   1732,    107, 111856,\n",
      "          14679,  23676,   3122,  14679,  14679,  13085, 170906, 111856,  80267,\n",
      "          14679,  14679,  14679,  13085,  80267,  80267, 101365,  14679,  48461,\n",
      "            107,  14679,  48461,  48461,  13085,  13085,  13085,    107,  48461,\n",
      "          14679,  14679,  14679,  14679,  14679,  14679,  14679,  14679,  14679,\n",
      "          14679,  14679,  48546, 128128,  24919]], device='cuda:0')\n",
      "output: [\"<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n கோض बन\\n,,חדחדחד\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n ب\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n B\\nに着\\nに着 ω ’ ’ ’\\n='') ’\\n ת\\n Vors\\n ’\\n ’\\n A\\n ’\\n ’\\n ’\\n ’\\n ) )\\n І ’ ’\\n Mol ’ )\\n Inoltre ’ )\\n Inoltre ’ І В ’ ’ ” fornire Inoltre)” ’ ’ ’ ”)”)” परत ’ Β\\n ’ Β Β ” ” ”\\n Β ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ Gian येते oso\"]\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:17<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            107,   5467,    107,   5467,  25575,    107,    107,    107,    107,\n",
      "            107,    107,    107,    107,    107,    107,  28443,   8772,    603,\n",
      "            107,    107,    107,    107,    107,    645,    107,    645,    107,\n",
      "           8772,    107,   8772,    107,    107,    107,    107, 111856,   2329,\n",
      "         242238,    107,    107,    107,    107,    538,    107, 182217,    107,\n",
      "            107,   3122, 241011,   3122,  15390,    107, 237146, 186761,    107,\n",
      "          61670,    107,    782,  25152,    107,   3122,    107, 236789,    107,\n",
      "            900,    107,   1781,    107,  24002,    107,  24002,    107,    107,\n",
      "           1732,    107,    997,    107,    107,    107,    107,   8772,    107,\n",
      "           3122,    107, 237146,   3122,    107,    107,   8772,    107,   1732,\n",
      "         148896,    107,  91175,    107,   1732,    107, 169060,    107, 169060,\n",
      "         236743,    107,    107, 111856,    107,    107, 111856,   8119, 167725,\n",
      "            107, 167725,    107, 111856,    107, 111856,  94728,    107,    107,\n",
      "         111856,    107, 111856,   8119,  23676,   3122,    107,   3122,    107,\n",
      "           3122,   3122]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n directly\\n directly unfortunately\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Dire Bu B\\n\\n\\n\\n\\n E\\n E\\n Bu\\n Bu\\n\\n\\n\\n Inoltre про̂\\n\\n\\n\\n n\\n stå\\n\\n В績 В \\'#\\nВ तपास\\n立ち\\n V Ба\\n В\\n\\'\\n +\\n.\"\\n...\"\\n...\"\\n\\n )\\n #\\n\\n\\n\\n Bu\\n В\\nВ В\\n\\n Bu\\n ) sicuro\\nuß\\n )\\n असू\\n असू \\n\\n Inoltre\\n\\n Inoltre З piens\\n piens\\n Inoltre\\n Inoltre Idi\\n\\n Inoltre\\n Inoltre З І В\\n В\\n В В']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model_en, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "139e09da-30d1-4174-9f5c-58a1d2f57349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:02<00:14,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761, 239867,   1311,   1311, 204805,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "         237577, 237577, 237577,  42622,   1311,   1311,   1311,  42622,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311]], device='cuda:0')\n",
      "output: ['<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.戰 по поポーチ по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по情情情 Healthcare по по по Healthcare по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:05<00:11,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "         237577,  42622,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311, 137013,   1311,\n",
      "           1311,   1311,   1311, 137013, 204805, 204805, 204805, 204805, 204805,\n",
      "         204805,  13772, 204805,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311, 137013,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311, 137013, 237577, 237577,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.情 Healthcare по по по по по по по по по по по по по по感兴趣 по по по по感兴趣ポーチポーチポーチポーチポーチポーチませんポーチ по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по感兴趣 по по по по по по по感兴趣情情 по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:08<00:08,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,   1311, 204805,\n",
      "          26269,   1311, 204805,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "         218500, 204805, 204805, 204805, 204805, 204805, 204805, 204805, 204805,\n",
      "         204805, 137013,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。 поポーチــ поポーチ по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по поropoポーチポーチポーチポーチポーチポーチポーチポーチポーチ感兴趣 по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:11<00:05,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,   1311,\n",
      "         239867,   1311, 204805, 204805, 204805, 204805, 204805,  42622,   1311,\n",
      "         204805, 204805, 204805, 204805, 204805, 204805, 204805, 204805, 204805,\n",
      "         137013,   1311,   1311,   1311, 137013, 204805, 204805, 204805, 204805,\n",
      "         204805, 204805, 204805, 204805, 204805, 137013, 204805, 204805, 137013,\n",
      "         204805, 204805, 204805, 137013, 137013, 137013, 204805, 204805, 204805,\n",
      "         204805, 204805, 204805,  42622, 137013,  42622, 239867, 239867,  42622,\n",
      "         239867, 239867,  12726,   1311, 204805, 137013, 204805, 239867, 239867,\n",
      "         239867,   1311, 239867,  42622,  42622, 239867, 239867,  90116, 204805,\n",
      "         137013, 204805, 137013, 204805, 137013, 204805, 137013, 204805, 239867,\n",
      "         239867,  90116, 204805, 137013,   1311, 239867,   1311, 239867, 239867,\n",
      "         239867, 239867, 125917, 239867, 237577, 204805, 137013, 204805, 137013,\n",
      "         204805, 137013, 204805, 137013, 204805, 239867, 239867,  42622,  42622,\n",
      "          42622,  12726,   1311, 137013, 204805, 137013, 204805, 137013,  42622,\n",
      "          42622,  12726,  12726,  42622,  42622,  42622,  42622,   1311, 204805,\n",
      "         204805]], device='cuda:0')\n",
      "output: ['<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top. по戰 поポーチポーチポーチポーチポーチ Healthcare поポーチポーチポーチポーチポーチポーチポーチポーチポーチ感兴趣 по по по感兴趣ポーチポーチポーチポーチポーチポーチポーチポーチポーチ感兴趣ポーチポーチ感兴趣ポーチポーチポーチ感兴趣感兴趣感兴趣ポーチポーチポーチポーチポーチポーチ Healthcare感兴趣 Healthcare戰戰 Healthcare戰戰 Market поポーチ感兴趣ポーチ戰戰戰 по戰 Healthcare Healthcare戰戰はありませんポーチ感兴趣ポーチ感兴趣ポーチ感兴趣ポーチ感兴趣ポーチ戰戰はありませんポーチ感兴趣 по戰 по戰戰戰戰affirm戰情ポーチ感兴趣ポーチ感兴趣ポーチ感兴趣ポーチ感兴趣ポーチ戰戰 Healthcare Healthcare Healthcare Market по感兴趣ポーチ感兴趣ポーチ感兴趣 Healthcare Healthcare Market Market Healthcare Healthcare Healthcare Healthcare поポーチポーチ']\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:14<00:02,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,  42622, 237577, 237577, 237577, 237577, 237577,\n",
      "           1311,  41162, 204805,   1311, 204805, 204805, 204805,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311]], device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao. Healthcare情情情情情 по以外ポーチ поポーチポーチポーチ по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:16<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "           1311, 204805, 204805, 204805, 204805, 204805,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,   1311,\n",
      "           1311,   1311]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。 поポーチポーチポーチポーチポーチ по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model_zh, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d40e6-f752-4877-a115-40076b8d9781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31247bde-41dd-4800-aa32-c9e77b806421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163eb0ea-829a-4296-8619-944f1d6eb0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c9da8c-15a1-4bb4-aed6-32a4424f0275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d35225f3-6a1c-408b-8508-c735147d4e37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "********************\n",
      "model name: org_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.2627, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 30.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(13.2703, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.5759, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_en_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.8695, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 30.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(12.3227, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.1235, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_vi_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 36.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(11.4861, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:32<00:00, 30.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(12.4606, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(10.1349, device='cuda:0')\n",
      "********************\n",
      "********************\n",
      "model name: mask_zh_neuron_model\n",
      "====================\n",
      "data name: en_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 37.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(9.6630, device='cuda:0')\n",
      "====================\n",
      "data name: vi_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:32<00:00, 30.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(8.8076, device='cuda:0')\n",
      "====================\n",
      "data name: zh_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:28<00:00, 35.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppl: tensor(9.0421, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "calc ppl\n",
    "\n",
    "'''\n",
    "\n",
    "# load test data\n",
    "test_en = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/en_radom_1000_test.jsonl')\n",
    "test_vi = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/vi_radom_1000_test.jsonl')\n",
    "test_zh = get_test_data('/root/autodl-fs/LRP_data/test_ppl_data/zh_radom_1000_test.jsonl')\n",
    "               \n",
    "# calc ppl\n",
    "model_list= [\n",
    "    (model, 'org_model'),\n",
    "    (model_en, 'mask_en_neuron_model'),\n",
    "    (model_vi, 'mask_vi_neuron_model'),\n",
    "    (model_zh, 'mask_zh_neuron_model'),\n",
    "]\n",
    "\n",
    "data_list = [\n",
    "    (test_en, 'en_data'),\n",
    "    (test_vi, 'vi_data'),\n",
    "    (test_zh, 'zh_data')\n",
    "    \n",
    "]\n",
    "\n",
    "for i_model, model_name in model_list:\n",
    "    print('*'*20)\n",
    "    print('*'*20)\n",
    "    print('model name:', model_name)\n",
    "\n",
    "    for i_data, data_name in data_list:\n",
    "        print('='*20)\n",
    "        print('data name:', data_name)\n",
    "        ppl_sum, ppl_count = calc_ppl(i_model, tokenizer, i_data, max_len= 2048)\n",
    "        print('ppl:',ppl_sum/ppl_count )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169fef85-50d7-42e7-98d1-2ec5bd02c6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a836eb-4e99-4408-a42b-2208d5b2a74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bceb5b-fb32-4b75-901b-2c822281a2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46635ecd-8fb8-4a08-a8c1-8bc38d417d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a22343d9-24ed-4a17-9873-c91ed8ce7e8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108,   7243,    108,   1018,   4968,\n",
      "          17243,  53121,    108,   7711,   2028,    563,    496,  29193, 236772,\n",
      "           5140,   5192,   2028,  15453,    580,    496,  12566,  15297,    529,\n",
      "           1816,    532,   3393,    528,   5422, 236764,  14361, 236764,   7830]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n---\\n\\n**Model Description:**\\n\\nOur model is a transformer-based language model trained on a massive dataset of text and code in English, Spanish, French']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            108,   1018, 236792, 237124,  14960, 140907,  90687,  27869,    568,\n",
      "           2182, 236792, 236768,    753,    623, 122850,   3271, 124468, 236775,\n",
      "           1018,    108, 122850,   3271, 124468,   3244,   7325,  38325,  14960,\n",
      "         140907,  90687,  27869,   7189,  55415]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n**Mô hình ngôn ngữ lớn (LLM) - \"LinguaVerse\"**\\n\\nLinguaVerse là một mô hình ngôn ngữ lớn được xây']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,   1018,\n",
      "          26609,  92141, 237184,   1018,    108, 236829,    139,   1018,  86313,\n",
      "         236743,  92141,  53121,    138,   6932,   5938,  39738,  92474,  10363,\n",
      "          26609, 236900,  99193, 158343,  26595,   9824,  11471,  27099,  10363,\n",
      "         238017, 237501, 236924]], device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n**模型架构：**\\n\\n*   **Transformer 架构:**  我们使用基于 Transformer 的模型，特别是 BERT 和 RoBERTa 的变体。']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "           7243,    108,    818,   6573,  54850,    657,   1041,  13925,   5716,\n",
      "         236764,    496,   4512, 236764,  74693,  89830, 236761,   3551,  11762,\n",
      "           3952,    528, 134880,   4314,    975, 236764,    496,   2173, 108507,\n",
      "           2342,    506, 162542,  16045]], device='cuda:0')\n",
      "output: ['<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\n---\\n\\nThe wind bites at my exposed skin, a constant, icy whisper. My breath comes in ragged gasps, a white plume against the bruised purple']\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108, 236769, 237703, 236748,   7439,  44693,\n",
      "         100634, 236764,  22947,  31612,  13940,  31889,  89158,   3884, 127379,\n",
      "          63719, 236768,    108,   1390,    108,   1390,    108,   1390,    108,\n",
      "         236769, 217366,  37513,   6256,   8665,  38143,  67946,  11188]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\n(Đoạn văn ngắn, tập trung vào cảm xúc và khung cảnh)\\n\\n...\\n\\n...\\n\\n...\\n\\n(Hãy thêm các chi tiết cụ thể']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108, 237169,  31799,  17583,  12680, 237408, 151599,  53877, 107462,\n",
      "         237206, 216348, 236924,  14201, 237169,  33813,  12553, 236900,  31799,\n",
      "          85694,  65407,  72245, 237622,  43719, 236924,  13488, 236900, 183868,\n",
      "          21181,  22276,  19695, 236900,  92711]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n我无法直接提供你登山者的情绪和视角。因为我是一个AI，无法模拟人类的情感体验。但是，我可以根据你的要求，创作']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38744ceb-319c-4b0d-8263-87369a92bc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27518f8a-3e32-49b2-bbcf-4bbb92337a10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108,   1018,   4968,  17243,  53121,\n",
      "            108,   7711,   2028,    563,    496,  29193, 236772,   5140,   5192,\n",
      "           2028, 236764,  10916,   5851, 236772, 100526,    580,    496,   2455,\n",
      "          15297,    529, 132567,   1816, 236761,   1030, 236789, 236751,   5402]],\n",
      "       device='cuda:0')\n",
      "output: [\"<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n**Model Description:**\\n\\nOur model is a transformer-based language model, specifically fine-tuned on a large dataset of multilingual text. It's designed\"]\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            108,   1018, 236792, 237124,  14960,  53121,    108, 172915,  21994,\n",
      "          16981,   7325,  38325,  14960,  92474, 236764,   7189, 200755, 100370,\n",
      "          14780,   7325,  22947,  79808,  35112,  27869,  43790,   6256,  44693,\n",
      "          28035,  48078, 140907,  90687, 236761]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n**Mô hình:**\\n\\nTôi sử dụng một mô hình Transformer, được huấn luyện trên một tập dữ liệu lớn gồm các văn bản đa ngôn ngữ.']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,   1018,\n",
      "          26609,  92141,  53121,    138,  39738,  86313,  92141, 236900,  31267,\n",
      "         238794,  42883, 236918,  37557,  26609, 236924,    107,   1018,  42883,\n",
      "           9676,  53121,    138,  37250,  41440,  15497,  37557, 236918,  57489,\n",
      "           9676, 236924,    107]], device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n**模型架构:**  基于Transformer架构，采用预训练的语言模型。\\n**训练数据:**  包含大量不同语言的文本数据。\\n']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "            818,   6573,    563,  85278, 236764,    496,   4512, 236764,  76789,\n",
      "          19211, 236761,   3551,  21367,    659,  62269, 236764,   1041,  19064,\n",
      "          50622, 236764,    840,    564,    740, 236789, 236745,   4721, 236761,\n",
      "            564, 236789,    560,   1010]], device='cuda:0')\n",
      "output: [\"<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\nThe wind is relentless, a constant, biting assault. My fingers are numb, my muscles screaming, but I can't stop. I've been\"]\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108,   7243,    108, 172915,  12105,  70669,\n",
      "          23946, 114589,  94509, 236761,    587,  21552,  30758,  47635,  16420,\n",
      "          10539,   7325, 231840,    518,   1592, 236764,   7325,  18457,  50014,\n",
      "         117434,  50464, 157104,  12835,  84641,    541, 239246, 236757]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\n---\\n\\nTôi đã leo lên đỉnh Everest. Mọi thứ bắt đầu như một cơn bão, một sự thôi thúc mạnh mẽ từ sâu thẳm']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108, 237169, 237282, 238493, 237408, 236900, 237169, 237282, 238493,\n",
      "         237408, 236900, 237169, 237282, 238493, 237408, 236900,    107, 237169,\n",
      "         237282, 238493, 237408, 236900, 237169, 237282, 238493, 237408, 236900,\n",
      "            107, 237169, 237282, 238493, 237408]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n我来找你，我来找你，我来找你，\\n我来找你，我来找你，\\n我来找你']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model_en, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f31be40b-23cb-4480-95cc-790f6e87c1f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108,   7243,    107,   8291, 236789,\n",
      "         236751,    496,   3435,   3072, 236787,    108, 236775,   4754,   2028,\n",
      "           6585, 132567,   2744,    684,  64004,    496,   8376,    529,    870,\n",
      "         109219,   2307,   8403,   1133, 236787,   4071, 236772, 187918, 106703]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\n---\\nHere\\'s a potential response:\\n\\n\"My model processes multilingual input by leveraging a combination of [mention key techniques like: cross-lingual embeddings']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            108,   1018, 236792, 237124,  14960,  53121,    108, 172915,  27600,\n",
      "          55415,  54380,   7325,  38325,  14960, 140907,  90687,  27869,    568,\n",
      "           2182, 236792, 236768,   4032,  63560,  26571,  86340,  28211,  79808,\n",
      "          35112,  48078, 140907,  90687, 236761]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\n\\n**Mô hình:**\\n\\nTôi đang xây dựng một mô hình ngôn ngữ lớn (LLM) có khả năng xử lý dữ liệu đa ngôn ngữ.']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,   1018,\n",
      "          26609,  26544,  53121,    870, 238350, 134451,  22276,  26609,  26544,\n",
      "         236900,  34313, 237184,  86313, 236764, 158343, 236764,   4044,  12120,\n",
      "            107,   1018,  26609,  92141,  53121,    870, 238350, 134451,  22276,\n",
      "          26609,  92141, 236900]], device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n**模型类型:** [请填写你的模型类型，例如：Transformer, BERT, etc.]\\n**模型架构:** [请填写你的模型架构，']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "            818,   6573,    563,    496,   4512, 236764, 214709,   1526, 236764,\n",
      "          34847,   3801,    657,   1041,  36326, 236764,    496,   7445, 236764,\n",
      "          14658,  32272,    529,    506,  37501,   2066,    529,    672,   1977,\n",
      "         236761,   3551,  11762,   3952]], device='cuda:0')\n",
      "output: ['<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\nThe wind is a constant, insistent hand, tugging at my harness, a cold, sharp reminder of the sheer power of this place. My breath comes']\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108,   7243,    108, 236780,  28416,  89158,\n",
      "           5042,  25969, 236787,    108, 236814,  29083,  10539,  27600,  70432,\n",
      "          13940,   7325,  21121,  32025,  23271, 236764,    107, 236773, 237644,\n",
      "            757, 204821,  29834,    719, 145515,  45222,  40515,  30758]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\n---\\n\\nCảm xúc của tôi:\\n\\nHóa như đang bước vào một thế giới mới,\\nSự im lặng bao trùm lấy mọi thứ']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108,   7243,    108, 237169,  79948, 239972, 241888, 240344, 241454,\n",
      "         239963, 239761, 239963, 236900, 239263, 237245, 237026, 239783, 206306,\n",
      "         240274, 238441, 236900, 238321, 239156, 239156, 237307, 240649, 237464,\n",
      "         236900,  57944, 239562, 239577, 236918]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n---\\n\\n我站在珠穆朗玛峰顶峰，脚下是冰冷的岩石，风呼呼地吹过，带来刺骨的']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model_vi, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1e3e9f52-a4ac-404c-a05c-c3c43205f6d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "input: Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\n",
      "input_ids: {'input_ids': tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   6974,    496,  63510,  15569,    529,   1217,    822,   2028,\n",
      "           6585, 132567,   2744,    532,   1217,    611,   5330,   9958,   3325,\n",
      "           3418,   1607,  15579, 236761,    108, 174355, 236764,    506,   2744,\n",
      "            563,    496,   3996, 236764,   5074, 236772, 172287, 236764,    532,\n",
      "          74647,  13186, 236761,    107,   2717,    107,   2717,    107,   2717,\n",
      "            107,   2717,    107,   2717,    107,   2717,    107,   2717,    107]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Write a concise explanation of how your model processes multilingual input and how you ensure consistent quality across different languages.\\n\\nEssentially, the input is a complex, multi-faceted, and interconnected entity.\\n```\\n```\\n```\\n```\\n```\\n```\\n```\\n']\n",
      "********************\n",
      "input: Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\n",
      "input_ids: {'input_ids': tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 217366,  28206,  35909, 100634,  96901,  20224,  38325,  14960,\n",
      "           5042,  10044,  86340,  28211,  79808,  35112,  48078, 140907,  90687,\n",
      "           3884,  14294,  21121,  22336,  11408,  70714,  32733,  23300,  21682,\n",
      "          23692,  37172,  39652,   6256, 140907,  90687,  22582,  26602, 236761,\n",
      "            107, 237703, 236916,   3244,   7325,  52898,  30170,    107, 237703,\n",
      "         236916,   3244,   7325,  52898,  30170,    107, 237703, 236916,   3244,\n",
      "           7325,  52898,  30170,    107, 237703, 236916,   3244,   7325,  52898,\n",
      "          30170,    107, 237703, 236916,   3244]], device='cuda:0')\n",
      "output: ['<bos>Hãy giải thích ngắn gọn cách mô hình của bạn xử lý dữ liệu đa ngôn ngữ và làm thế nào để đảm bảo chất lượng đồng đều giữa các ngôn ngữ khác nhau.\\nĐó là một vấn đề\\nĐó là một vấn đề\\nĐó là một vấn đề\\nĐó là một vấn đề\\nĐó là']\n",
      "********************\n",
      "input: 请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\n",
      "input_ids: {'input_ids': tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2, 238350, 238686, 237208,  36116,  22276,  26609, 164881,  19157,\n",
      "         237309,  37557, 180828, 236900,  17375, 237408,  19809,  62247,  15497,\n",
      "          37557,  56695,  33232,  33783,  36267,  55682, 236924,    108,  26609,\n",
      "          42883,   9676,  19157,  33783,  42050,  55682, 237409, 237184,    107,\n",
      "          42883,   9676,  19157,  33783,  42050,  55682, 237409, 237184,  42883,\n",
      "           9676,  19157,  33783,  42050,  55682, 237409, 237184,  42883,   9676,\n",
      "          19157,  33783,  42050]], device='cuda:0')\n",
      "output: ['<bos>请简要说明你的模型是如何处理多语言输入的，以及你如何确保不同语言之间的输出质量保持一致。\\n\\n模型训练数据处理质量保证一致性：\\n训练数据处理质量保证一致性：训练数据处理质量保证一致性：训练数据处理质量保证']\n",
      "********************\n",
      "input: You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\n",
      "input_ids: {'input_ids': tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,   3048,    659,    496, 113768,   1015,    815,   8452,    506,\n",
      "          34976,    529,   9348,  94509, 236761,  54234,    822,  19979,    532,\n",
      "            506,   1927,    611,   1460,    699,    506,   1903, 236761,    108,\n",
      "           1018,    108,   1018,    108,   1018,    108,   1018,    108,   1018,\n",
      "            108,   1018,    108,   1018,    108,   1018,    108,   1018,    108,\n",
      "           1018,    108,   1018,    108,   1018,    108,   1018,    108,   1018,\n",
      "            108,   1018,    108,   1018]], device='cuda:0')\n",
      "output: ['<bos>You are a climber who has reached the summit of Mount Everest. Describe your emotions and the view you see from the top.\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**\\n\\n**']\n",
      "********************\n",
      "input: Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\n",
      "input_ids: {'input_ids': tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[     2,  99972,   3244,   7325,  10279,  70669, 121230,  50971, 232727,\n",
      "          57703, 114589,  94509, 236761,  88170,  38325, 110624,  31889,  89158,\n",
      "           5042,  10044,   3884, 127379,  63719,  10044,  51414,  27888,  12835,\n",
      "          14780,  21587, 236761,    108,  99972,  31889,  89158,   5042,  10044,\n",
      "           3884, 127379,  63719,  10044,  51414,  27888,  12835,  14780,  21587,\n",
      "         236761,    107, 237703,    581,  31889,  89158,   5042,  10044,   3884,\n",
      "         127379,  63719,  10044,  51414,  27888,  12835,  14780,  21587]],\n",
      "       device='cuda:0')\n",
      "output: ['<bos>Bạn là một người leo núi vừa chinh phục đỉnh Everest. Hãy mô tả cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\n\\nBạn cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao.\\nĐem cảm xúc của bạn và khung cảnh bạn nhìn thấy từ trên cao']\n",
      "********************\n",
      "input: 你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\n",
      "input_ids: {'input_ids': tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n",
      "outputs: tensor([[     2, 237408, 213062, 223874, 239972, 241888, 240344, 241454, 239963,\n",
      "         239761, 239963, 236918, 151599, 237457, 236924,  47710,  19757,  22276,\n",
      "         107462, 236900,  17375, 237900, 237390, 238097, 187945, 143572, 236924,\n",
      "            108,    106]], device='cuda:0')\n",
      "output: ['<bos>你是一位登上珠穆朗玛峰顶峰的登山者。描述一下你的情绪，以及从高处看到的景色。\\n\\n<end_of_turn>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate(model_zh, tokenizer, textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e9af8-a950-4a96-8660-21d6006b5f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d2e63-45ff-481c-9545-a1e80541deee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
